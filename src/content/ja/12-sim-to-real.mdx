import { MathBlock } from "@/components/math/MathBlock";
import { CodeEditor } from "@/components/code/CodeEditor";
import { InteractiveDemo } from "@/components/visualization/InteractiveDemo";
import { SimToRealPipelineDiagram } from "@/components/diagrams/SimToRealDiagram";

# シミュレーションから実機への転移

シミュレーション内での歩行方策の学習は高速かつ安全ですが、実際のロボットへの転移は**シミュレーションと実機のギャップ**（シミュレーションと実世界の物理の違い）のため困難です。

<SimToRealPipelineDiagram />

## シミュレーションと実機のギャップ

シミュレーションと現実の間の不一致の原因:

| 原因 | 例 |
|--------|---------|
| **ダイナミクス** | 不正確な質量、摩擦、接触モデル |
| **アクチュエータ** | モータ遅延、トルク制限、バックラッシュ |
| **センサ** | ノイズ、バイアス、キャリブレーション誤差 |
| **環境** | 地形の変化、風、障害物 |

## ドメインランダム化

**ドメインランダム化**は、シミュレーションパラメータの広い分布にわたって方策を学習させ、変動に対してロバストにします。

### 何をランダム化するか

$$
\xi \sim \mathcal{U}(\xi_{min}, \xi_{max})
$$

| パラメータ | 典型的な範囲 |
|-----------|--------------|
| 質量 | 公称値の $\pm 30\%$ |
| 摩擦 | $[0.3, 1.5]$ |
| モータ強度 | $\pm 20\%$ |
| センサノイズ | $\sigma \in [0, 0.05]$ |
| 動作遅延 | $[0, 30]$ ms |
| 地面の傾斜 | $\pm 5°$ |

<CodeEditor
  initialCode={`import random
import math

# Domain randomization demonstration
random.seed(42)

class RandomizedEnvironment:
    """LIPM with randomized parameters."""
    def __init__(self):
        self.randomize()

    def randomize(self):
        """Randomize physics parameters."""
        nominal_mass = 30.0
        nominal_height = 0.8
        nominal_friction = 0.8

        self.mass = nominal_mass * random.uniform(0.7, 1.3)
        self.z_c = nominal_height * random.uniform(0.85, 1.15)
        self.friction = nominal_friction * random.uniform(0.5, 1.5)
        self.motor_delay = random.uniform(0, 0.03)
        self.sensor_noise = random.uniform(0, 0.02)
        self.g = 9.81

        self.omega = math.sqrt(self.g / self.z_c)

    def get_params_str(self):
        return (f"mass={self.mass:.1f}kg, z_c={self.z_c:.3f}m, "
                f"friction={self.friction:.2f}, delay={self.motor_delay*1000:.0f}ms")

# Show parameter distributions across environments
print("=== Domain Randomization: Parameter Samples ===")
print()
print("Env  Mass(kg)  Height(m)  Friction  Delay(ms)  omega(rad/s)")
print("-" * 65)

env = RandomizedEnvironment()
omega_values = []

for i in range(10):
    env.randomize()
    omega_values.append(env.omega)
    print(f" {i:2d}   {env.mass:6.1f}     {env.z_c:.3f}     "
          f"{env.friction:.2f}      {env.motor_delay*1000:4.1f}       "
          f"{env.omega:.3f}")

print()
avg_omega = sum(omega_values) / len(omega_values)
std_omega = math.sqrt(sum((w - avg_omega)**2 for w in omega_values) / len(omega_values))
print(f"omega range: [{min(omega_values):.3f}, {max(omega_values):.3f}]")
print(f"omega mean: {avg_omega:.3f}, std: {std_omega:.3f}")
print()

# Simulate effect on walking
print("=== Effect on Walking Behavior ===")
print()
print("With a fixed controller, different environments produce:")
print()

for i in range(5):
    env.randomize()
    # Simple walking step with LIPM
    x = -0.05
    xdot = 0.3
    dt = 0.01
    step_time = 0.5

    for _ in range(int(step_time / dt)):
        xddot = env.omega**2 * x  # simplified
        xdot += xddot * dt
        x += xdot * dt

    print(f"  Env {i}: omega={env.omega:.3f} -> final_x={x:.4f}m, "
          f"vel={xdot:.4f}m/s")

print()
print("A robust policy must handle all these variations!")
`}
/>

## システム同定

すべてをランダム化する代わりに、**システム同定**は実際のロボットのパラメータを測定してシミュレーション精度を向上させます。

### オンラインシステム同定

展開中にパラメータを推定します:

$$
\hat{\xi}_{k+1} = \hat{\xi}_k + K_k(y_k - \hat{y}_k(\hat{\xi}_k))
$$

ここで $\hat{\xi}$ はパラメータ推定値、$y_k$ は計測出力、$K_k$ は適応ゲインです。

## 高速モータ適応 (RMA)

RMAはドメインランダム化とオンライン適応の利点を組み合わせます:

1. **基本方策** $\pi(a | s, z)$: 状態と環境埋め込み $z$ を入力として受け取る
2. **適応モジュール** $\hat{z} = f(s_{t-H:t})$: 最近の状態履歴から $z$ を推定

学習時（シミュレーション）:
- 特権的な環境情報 $z$ を用いて基本方策を学習
- 状態履歴から $z$ を予測する適応モジュールを学習

展開時（実ロボット）:
- 適応モジュールがセンサデータからオンラインで $z$ を推定
- 基本方策が推定された $z$ を使用して行動

<CodeEditor
  initialCode={`import math
import random

# Simplified Rapid Motor Adaptation concept
random.seed(42)

# Environment parameters (the "latent" z)
true_params = {
    "mass_ratio": 1.2,     # 20% heavier than nominal
    "friction": 0.6,       # lower friction
    "motor_strength": 0.9,  # 10% weaker motors
}

# Simulate state history with these parameters
def simulate_step(x, v, force, mass_ratio, friction):
    dt = 0.01
    a = force / (30.0 * mass_ratio) - friction * v * 0.1
    v_new = v + a * dt
    x_new = x + v_new * dt
    return x_new, v_new

# Generate state history
print("=== Rapid Motor Adaptation Demo ===")
print()
print("True environment parameters:")
for k, v in true_params.items():
    print(f"  {k}: {v}")
print()

history = []
x, v = 0.0, 0.0
for t in range(50):
    force = 5.0 * math.sin(t * 0.2)  # probing signal
    x, v = simulate_step(x, v, force,
                          true_params["mass_ratio"],
                          true_params["friction"])
    history.append((x, v, force))

# "Adaptation module": estimate parameters from history
# (In practice, this is a neural network)
# Simple estimation: use response characteristics
responses = [h[1] for h in history[10:]]  # velocities
forces = [h[2] for h in history[10:]]

# Estimate mass ratio from force-acceleration relationship
accels = [(responses[i+1] - responses[i]) / 0.01 for i in range(len(responses)-1)]
avg_response = sum(abs(a) for a in accels) / len(accels)
nominal_response = 0.17  # expected for nominal params
estimated_mass_ratio = nominal_response / avg_response * 1.0

# Estimate friction from velocity decay
vel_decay = sum(abs(responses[i+1]) - abs(responses[i])
                for i in range(len(responses)-1) if abs(forces[i]) < 0.1)

print("Adaptation module estimates:")
print(f"  mass_ratio: {estimated_mass_ratio:.2f} (true: {true_params['mass_ratio']:.2f})")
print()
print("With adaptation, the policy adjusts its behavior:")
print("  - Heavier mass -> stronger push-off")
print("  - Lower friction -> shorter steps")
print("  - Weaker motors -> conservative gait")
`}
/>

## シミュレーションから実機への主要な成果

| 年 | システム | 手法 | 成果 |
|------|--------|--------|-------------|
| 2018 | Cassie | ドメインランダム化 | 屋外歩行 |
| 2020 | ANYmal | 教師-生徒学習 | ブラインド歩行 |
| 2023 | Digit | RMA | マルチ地形対応 |
| 2024 | 各種 | 大規模RL | アジャイルヒューマノイド歩行 |

## 参考文献

- J. Tobin et al., "[Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World](https://arxiv.org/abs/1703.06907)," *Proc. IROS*, 2017.
- I. Radosavovic et al., "[Real-World Humanoid Locomotion with Reinforcement Learning](https://arxiv.org/abs/2303.03381)," *Science Robotics*, 2024.
- A. Kumar et al., "[RMA: Rapid Motor Adaptation for Legged Robots](https://arxiv.org/abs/2107.04034)," *RSS*, 2021.

<InteractiveDemo title="Domain Randomization Visualization">
  <p className="text-sm text-gray-500">
    Interactive domain randomization parameter visualization coming soon.
  </p>
</InteractiveDemo>
