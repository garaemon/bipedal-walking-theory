import { MathBlock } from "@/components/math/MathBlock";
import { InteractiveDemo } from "@/components/visualization/InteractiveDemo";
import { FrontiersTaxonomyDiagram } from "@/components/diagrams/FrontiersTaxonomyDiagram";

# 二足歩行の最前線

本章では、Transformerベースのコントローラからアジャイルなヒューマノイドスキルまで、二足歩行の限界を押し広げる最先端の研究を概観します。また、前章までに学んだ古典的手法が、これらの最先端システムにおいても不可欠な構成要素であることを示します。

<FrontiersTaxonomyDiagram />

## Transformerベースの歩行コントローラ

最近の研究ではTransformerアーキテクチャが歩行制御に適用されています。現在の観測のみを入力とする標準的なMLP方策とは異なり、Transformerは**状態の履歴**を処理し、現在の判断に関連する過去の観測を学習によって選択できます。

### Transformerの歩行制御への適用方法

基本的なアイデアは、文章中の単語のように、状態の履歴をトークンの系列として扱うことです。履歴窓の長さを$H$とすると:

$$
\mathbf{s}_{t-H},\; \mathbf{s}_{t-H+1},\; \ldots,\; \mathbf{s}_t
$$

各状態$\mathbf{s}_i$（関節角度、角速度、体幹姿勢などを含む）は、学習された線形層によって**トークン埋め込み**に変換されます:

$$
\mathbf{z}_i = W_{\text{proj}} \, \mathbf{s}_i + \mathbf{b}_{\text{proj}}
$$

これらの埋め込みはTransformer層の**Self-Attention**によって処理され、モデルは過去のどの状態が現在の判断に有用な情報を持っているかを学習します。最終的に、最後の位置の出力から行動が得られます:

$$
a_t = f_{\text{head}}(\text{TransformerEncoder}(\mathbf{z}_{t-H}, \ldots, \mathbf{z}_t))
$$

これは大規模言語モデルにおけるTransformerの使い方とは根本的に異なります。系列の自己回帰生成は行わず、各制御ステップ（通常50-100Hz）で**1回のフォワードパス**により1つの行動を予測します。

### MLP方策に対する主な利点

- **可変長の履歴処理**: Attention機構は固定サイズの観測スタッキングとは異なり、様々な履歴長を自然に扱える
- **時間パターンの学習**: Self-Attentionは、例えば10ステップ前の足接地イベントが現在の地面反力を予測するといった関係を発見できる
- **文脈内適応**: 十分な履歴があれば、明示的なシステム同定なしに地形特性（摩擦、傾斜）を暗黙的に推定
- **マルチタスク学習**: コマンドトークンで条件付けすることで、単一のTransformerモデルで歩行、旋回、速度変更に対応

### クロスエンボディメント転移

多様なロボット形態で学習された基盤モデルは、異なるヒューマノイドプラットフォーム間で歩行スキルを転移できます。鍵となるアイデアは、歩行行動の共有潜在空間を学習することで、あるロボットで学習した方策を最小限の微調整で別のロボットに適応させることです。

## ヒューマノイドのアジャイルスキル

### マルチエージェントロボットサッカー

ヒューマノイドロボットによる自律的なサッカーは、最も要求の厳しいマルチエージェント歩行課題の一つです:

- **動的なキック**と全身協調: 高い足先速度を生成しながらバランスを維持する必要がある
- **多様な姿勢からの起き上がり**: 学習された回復方策が任意の転倒姿勢に対応
- **マルチエージェント協調**: 中央制御なしに戦略を共有し、衝突を回避し、パスを協調する
- **リアルタイム視覚ベースの相手追跡**: 搭載カメラと限られた計算資源で効率的な知覚を実現

Haarnoja et al. (2024) は、深層RLでシミュレーション内で完全に学習した方策を実機に転移し、二足歩行ロボットのチームによるサッカーを実証しました。

### パルクール

自律パルクールには知覚、計画、制御のシームレスな統合が必要です:

- **知覚**: 深度センサによるリアルタイム3D地形マッピング
- **計画**: ギャップ、壁、高台などの障害物を通る実行可能な経路の選択
- **制御**: 高力ジャンプの生成、精密な着地、空中での体幹姿勢制御
- **タイミング**: 飛行フェーズ中の軌道変更不可能な瞬間での判断

Cheng et al. (2024) と Zhuang et al. (2023) は四足歩行ロボットでのパルクールを実証し、同様の技術が二足歩行ロボットへ拡張されつつあります。

### 走行とジャンプ

アジャイルな二足走行には以下が含まれます:

- **飛行フェーズ**: 両足が地面から離れ、弾道軌道の予測が必要
- **高衝撃の着地吸収**: コンプライアント関節制御による衝撃緩和
- **動的安定性**: 飛行中に支持多角形が消失するため、歩行用に設計されたZMP/DCMの枠組みを超えた安定性が必要

## 視覚ベースの歩行

視覚を歩行コントローラに統合することで、事前の地図なしに複雑な地形を走破できるようになります。主に2つのアーキテクチャが存在します。

### アプローチ1: エンドツーエンド学習

方策は固有受容データと生のカメラ画像から直接行動にマッピングします:

$$
a_t = \pi_\theta(\mathbf{o}^{\text{proprio}}_t, \mathbf{o}^{\text{visual}}_t)
$$

このアプローチは概念的にシンプルですが、大量の学習データが必要であり、照明条件やカメラ設定の変化に対する汎化が困難です。

### アプローチ2: 高さマップによる知覚パイプライン

より分割されたアプローチは、知覚と制御を分離します:

1. **深度画像から高さマップへ**: 深度カメラがシーンを撮影し、ロボット周囲の地形を2Dグリッドの高さ値に離散化（例: 各足の周囲1mをカバーする5cm解像度の20x20グリッド）
2. **特徴抽出**: 畳み込みニューラルネットワーク（CNN）が高さマップを処理し、段差、傾斜、ギャップなどの地形特徴を抽出
3. **方策への入力**: 抽出された特徴を固有受容状態と結合し、歩行方策に入力
4. **分離学習**: 知覚モジュールと歩行方策を独立に学習でき、各学習問題が簡素化

### センサレイテンシの管理

重要な実践的課題は**センサレイテンシ**です。深度カメラは通常30Hzで動作し、30-60msの処理遅延があります。この遅延中にロボットは移動を続けるため、コントローラが受け取る時点で知覚された地形はすでに古くなっています。対策としては:

- **状態予測**: ロボットの運動学モデルを用いて、レイテンシ分だけ現在の状態を前方予測
- **観測遅延のランダム化**: 学習中に視覚観測をランダムに遅延させ、可変レイテンシに対してロバストな方策を獲得
- **固有受容による上書き**: 視覚と固有受容の情報が矛盾する場合、即座のバランスには固有受容を信頼

### 実世界での成果

視覚ベースの歩行は実機で印象的な成果を達成しています:
- **ANYmal**（ETH Zurich）: 学習された高さマップ推定による階段昇降と不整地走破
- **Cassie**（Oregon State / Agility Robotics）: 深度カメラを用いた多様な地形での屋外歩行
- これらのシステムは、Sim-to-Real転移（第12章）がビジョンインザループ展開に十分成熟していることを示している

## 大規模学習

現代の歩行学習は、GPU加速物理シミュレーションによる大規模並列化に依存しています。

### GPU加速物理エンジン

MuJoCoやBulletなどの従来のCPUベースシミュレータはCPUコアあたり1環境を実行します。GPU加速エンジンはスケーリングを根本的に変えます:

- **IsaacGym**（NVIDIA）: シミュレーション全体と方策のフォワードパスを単一のGPU上で実行し、CPU-GPU間のデータ転送を回避
- **MJX**（MuJoCo XLA）: MuJoCoの物理をXLAにコンパイルし、JAXベースのベクトル化シミュレーションを実現
- **Brax**: JAXで記述された微分可能な物理エンジンで、TPU/GPU並列処理に最適化

### RLにおいて並列化が重要な理由

鍵となる洞察は、強化学習では**少数の環境で長時間学習するよりも、多数の並列環境を使う方がほぼ常に効率的**であるということです。その理由は:

| 要素 | 規模 |
|--------|-------|
| 並列環境 | 4,000 - 100,000 |
| 実時間学習時間 | 10分 - 24時間 |
| GPU | 1 - 64 GPU |
| シミュレーションステップ | $10^9$ - $10^{11}$ |

- **バッチ効率**: すべての環境が同じGPUメモリと物理カーネルを共有するため、環境数を倍にしても計算コストは倍にならない
- **探索の多様性**: 数千のロボットが同時に異なる状態を探索し、サンプルカバレッジが劇的に改善
- **実時間の短縮**: CPUクラスタで数日かかっていた学習が、単一GPUで数時間に短縮

### ベクトル化環境アーキテクチャ

ベクトル化された構成では、全$N$体のロボットが単一のバッチテンソル演算としてシミュレーションされます。全ロボットの状態$\mathbf{S} \in \mathbb{R}^{N \times d}$が同時に更新され、方策は全観測を1回のバッチフォワードパスで評価します。これにより、CPUベースの並列学習を悩ませるPythonループやプロセス間通信のオーバーヘッドが排除されます。

## ロコマニピュレーション

歩行と物体操作の統合は、**操作力が歩行バランスを直接乱す**ため、最も困難な未解決問題の一つです。

### 核心的な課題

ヒューマノイドロボットが物体を押す、引く、運搬する際、操作による接触力が歩行コントローラへの外乱として作用します。ロボットは以下を達成する必要があります:

- **バランス外乱の予測**: 物体を把持・移動することで重心がどのようにシフトし、反力が発生するかを予測
- **全身運動の協調**: 腕の動きが上半身の有効慣性を変えるため、腕軌道と脚のステッピングを同時に計画
- **安定余裕の維持**: 操作力が変動しても、ZMP（第3章）が支持多角形内に留まることを保証

### 現在のアプローチ

最新の手法は、腕と脚の関節指令の両方を含む全身運動を出力するエンドツーエンド方策を学習します:

- **階層的制御**: 上位方策が操作と歩行のサブゴールを選択し、下位の全身コントローラ（第8章）が実行可能な関節軌道を生成
- **統合方策**: 単一のニューラルネットワークが全関節指令を同時に出力し、腕の動きとバランスの結合を学習
- **接触考慮型計画**: 多様な物体インタラクションで方策を学習し、可変の摩擦と質量に対応

### 最近の研究例

- 平地および不整地を歩行しながら、様々な重さの箱を運搬するヒューマノイドロボット
- ドアの開閉: 手で引く/押す力と転倒を防ぐステッピング動作の協調
- 道具の使用: バランスを維持しながらの鍵の挿入、ボタンの操作、レバーの操作

## 最前線システムにおける基礎理論の活用

学生にとって重要な洞察は、最先端の研究が古典的手法を**捨てていない**ということです。むしろ、傾向は古典的な構造と学習コンポーネントを組み合わせた**ハイブリッドアーキテクチャ**へ向かっています。

### 現在も使われている古典的手法

- **ZMP（第3章）**: 学習ベースのシステムでも、ZMP制約は安定領域の定義やRL学習中の報酬項として使用
- **DCM（第6章）**: 運動の発散成分は、学習された歩行方策を補完する押し回復モジュールに使用
- **全身制御（第8章）**: QPベースのコントローラが学習された上位方策の下位層として機能。ニューラルネットワークが目標タスク空間指令を出力し、QPソルバが接触制約やトルク制限を満たす実行可能な関節トルクに変換
- **HZD（第9章）**: Hybrid Zero Dynamicsは数学的に構造化された制約を提供し、学習ベースの最適化を正則化して、学習された歩容が物理的な周期性を尊重するよう保証

### コア学習パイプライン

- **強化学習（第11章）**: 最適化フレームワークを提供。望ましい行動を符号化する報酬関数を定義し、PPOやSACで方策を学習
- **Sim-to-Real転移（第12章）**: ドメインランダム化、システム同定、適応モジュールによりシミュレーションと現実のギャップを橋渡し
- これらが合わさって、ほぼすべての最先端歩行研究のバックボーンを形成

### ハイブリッドアーキテクチャパターン

最近の研究で支配的なパターンは:

$$
\text{Learned high-level policy} \;\xrightarrow{\text{task commands}}\;
\text{Classical low-level controller (WBC/QP)}
$$

この階層的アプローチは、学習の適応性と古典制御の安全保証および物理的整合性を組み合わせます。学習された方策が地形適応と高次判断を担い、古典コントローラが実行可能で安全な関節レベルの実行を保証します。

## 主要なブレークスルーの年表

| 年 | マイルストーン | 意義 |
|------|-----------|------|
| 1969 | ZMP概念 (Vukobratovic) | 二足歩行の最初の厳密な安定性基準を提供し、モデルベースの歩容生成を可能にした |
| 1990 | 受動的動歩行 (McGeer) | 能動的制御なしに力学のみから歩行が生じることを実証し、エネルギー効率の良い設計に着想を与えた |
| 2001 | 歩行のための3D-LIPM (Kajita) | 複雑な3D歩行問題を扱いやすい線形モデルに帰着し、リアルタイム歩容計画を可能にした |
| 2003 | ZMPプレビュー制御 (Kajita) | 将来の参照ZMP軌道を先読みすることで、滑らかで安定した歩容を実現 |
| 2006 | キャプチャーポイント / DCM (Pratt) | 1ステップの安定性基準を導入し、押し回復とバランス制御を簡素化 |
| 2014 | 実機でのHZD (Ames) | Hybrid Zero Dynamicsの数学的枠組みを実際の二足歩行ロボット（DURUS）で検証 |
| 2018 | DeepMimic (Peng) | RLエージェントがモーションキャプチャデータの模倣により、高度に動的でリアルな動作を学習できることを示した |
| 2019 | Cassieのシム・トゥ・リアル (Xie) | Cassie二足歩行ロボットにおけるRL学習歩行方策の初めてのSim-to-Real転移成功 |
| 2023 | 実世界ヒューマノイドRL (Radosavovic) | 屋外環境においてフルサイズヒューマノイドロボットでのエンドツーエンドRL学習歩行を実証 |
| 2024 | アジャイルヒューマノイドスキル (Haarnoja, Cheng) | 大規模RL学習とSim-to-Real転移によるヒューマノイドロボットのサッカーとパルクールを達成 |
| 2025 | 歩行のための基盤モデル | 異なるロボット形態間で歩行スキルを汎化するクロスエンボディメントTransformerモデル |

## 未解決問題

### 1. エネルギー効率
RLで学習された歩容は、受動的動歩行器の3-5倍のエネルギーを使用することが多いです。受動的動歩行（第2章）のエネルギー効率の良い設計原理と学習をどのように組み合わせられるでしょうか？

### 2. 長期的な計画
現在のコントローラは反応的です。実世界のナビゲーションには、経路の選択、地形変化の予測、エネルギー予算の管理など、数分先の計画が必要です。

### 3. ロバストな知覚
雨、雪、暗闇、信頼性の低いセンサを伴う雑然とした環境での動作は、視覚ベースのシステムにとって依然として困難です。

### 4. 安全性と検証
学習されたコントローラが危険な行動を決して取らないことをどのように保証できるでしょうか？ニューラルネットワーク方策の形式検証は、現在活発に研究されている分野です。

### 5. 人間とロボットのインタラクション
人間と並んで歩行する、運搬する、または身体的に支援するには、人間の意図の理解とコンプライアント制御による安全性の確保が必要です。

## 参考文献

- T. Haarnoja et al., "[Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning](https://arxiv.org/abs/2304.13653)," *Science Robotics*, 2024.
- I. Radosavovic et al., "[Humanoid Locomotion as Next Token Prediction](https://arxiv.org/abs/2402.19469)," *arXiv*, 2024.
- Z. Zhuang et al., "[Robot Parkour Learning](https://arxiv.org/abs/2309.05665)," *CoRL*, 2023.
- X. Cheng et al., "[Extreme Parkour with Legged Robots](https://arxiv.org/abs/2309.14341)," *ICRA*, 2024.
- J. Lee et al., "[Learning Quadrupedal Locomotion over Challenging Terrain](https://arxiv.org/abs/2010.11251)," *Science Robotics*, 2020.
- T. Miki et al., "[Learning robust perceptive locomotion for quadrupedal robots in the wild](https://arxiv.org/abs/2201.08117)," *Science Robotics*, 2022.
- V. Makoviychuk et al., "[Isaac Gym: High Performance GPU-Based Physics Simulation For Robot Learning](https://arxiv.org/abs/2108.10470)," *NeurIPS*, 2021.

<InteractiveDemo title="Research Frontier">
  <p className="text-sm text-gray-500">
    Explore the latest papers and demos in bipedal locomotion research.
  </p>
</InteractiveDemo>
