import { MathBlock } from "@/components/math/MathBlock";
import { InteractiveDemo } from "@/components/visualization/InteractiveDemo";

# 二足歩行の最前線

本章では、Transformerベースのコントローラからアジャイルなヒューマノイドスキルまで、二足歩行の限界を押し広げる最先端の研究を概観します。

## Transformerベースの歩行コントローラ

最近の研究ではTransformerアーキテクチャが歩行制御に適用されています:

### 歩行Transformer

反応的な方策の代わりに、Transformerは**観測の系列**を処理して意思決定を行います:

$$
a_t = f_{transformer}(o_{t-H}, o_{t-H+1}, \ldots, o_t)
$$

主な利点:
- **長期的な推論**: 関連する過去の事象に注目
- **文脈内適応**: 再学習なしに新しい地形に適応
- **マルチタスク学習**: 単一モデルで多様な歩行タスクに対応

### クロスエンボディメント転移

多様なロボット形態で学習された基盤モデルは、異なるヒューマノイドプラットフォーム間で歩行スキルを転移できます。

## ヒューマノイドのアジャイルスキル

### サッカー

ヒューマノイドロボットによる自律的なサッカー:
- 全身協調による動的なキック
- 多様な姿勢からの起き上がり
- マルチエージェント協調と戦略
- リアルタイム視覚ベースの相手追跡

### パルクール

自律パルクールには以下が必要です:
- **知覚**: リアルタイム3D地形マッピング
- **計画**: 障害物を通る実行可能な経路の選択
- **制御**: 高力ジャンプ、精密な着地、回復
- **タイミング**: 飛行フェーズ中の瞬間的な判断

### 走行とジャンプ

アジャイルな二足走行には以下が含まれます:
- 飛行フェーズ（両足が地面から離れる）
- 高衝撃の着地吸収
- ZMP/DCMの枠組みを超えた動的安定性

## 視覚ベースの歩行

明示的な地形マップをエンドツーエンドの学習された知覚に置き換えます:

$$
a_t = \pi_\theta(o^{proprio}_t, o^{visual}_t)
$$

方策は固有受容データとカメラ画像から直接行動にマッピングします。

### 課題
- **レイテンシ**: 視覚処理は反応的な制御に十分な速さが必要
- **ロバスト性**: 照明変化、遮蔽、モーションブラーへの対応
- **汎化**: 未知の地形や環境での動作

### 高さマップ推定

中間表現を用いたアプローチ:
1. 深度カメラからローカルな地形高さマップを推定
2. 高さマップと固有受容を歩行方策に入力
3. 知覚の学習と歩行の学習を分離

## 大規模学習

現代のアプローチは大規模な計算資源を活用します:

| 要素 | 規模 |
|--------|-------|
| 並列環境 | 4,000 - 100,000 |
| 学習時間 | 10分 - 24時間 |
| GPU | 1 - 64 GPU |
| シミュレーションステップ | $10^9$ - $10^{11}$ |

主要なイネーブラ: GPU加速物理シミュレーション（IsaacGym、MuJoCo XLA、Brax）により、数千の環境を並列実行。

## 未解決問題

### 1. 全身ロコマニピュレーション
歩行と物体操作の組み合わせには、歩行安定性とアーム/ハンドの力の協調が必要です。

### 2. エネルギー効率
RLで学習された歩容は、受動的動歩行器の3-5倍のエネルギーを使用することが多いです。学習とエネルギー効率の良い設計原理をどのように組み合わせられるでしょうか？

### 3. 長期的な計画
現在のコントローラは反応的です。実世界のナビゲーションには、経路の選択、地形変化の予測、エネルギー予算の管理など、数分先の計画が必要です。

### 4. ロバストな知覚
雨、雪、暗闇、信頼性の低いセンサを伴う雑然とした環境での動作は依然として困難です。

### 5. 安全性と検証
学習されたコントローラが危険な行動を決して取らないことをどのように保証できるでしょうか？ニューラルネットワーク方策の形式検証は、現在活発に研究されている分野です。

### 6. 人間とロボットのインタラクション
人間と並んで歩行する、運搬する、または身体的に支援するには、人間の意図の理解と安全性の確保が必要です。

## 主要なブレークスルーの年表

| 年 | マイルストーン |
|------|-----------|
| 1969 | ZMP概念 (Vukobratovic) |
| 1990 | 受動的動歩行 (McGeer) |
| 2001 | 歩行のための3D-LIPM (Kajita) |
| 2003 | ZMPプレビュー制御 (Kajita) |
| 2006 | キャプチャーポイント (Pratt) |
| 2014 | 実機でのHZD (Ames) |
| 2018 | DeepMimic (Peng) |
| 2019 | Cassieのシム・トゥ・リアル (Xie) |
| 2023 | 実世界ヒューマノイドRL (Radosavovic) |
| 2024 | アジャイルヒューマノイドスキル (Haarnoja, Cheng) |
| 2025 | 歩行のための基盤モデル |

## 参考文献

- T. Haarnoja et al., "[Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning](https://arxiv.org/abs/2304.13653)," *Science Robotics*, 2024.
- I. Radosavovic et al., "[Humanoid Locomotion as Next Token Prediction](https://arxiv.org/abs/2402.19469)," *arXiv*, 2024.
- Z. Zhuang et al., "[Robot Parkour Learning](https://arxiv.org/abs/2309.05665)," *CoRL*, 2023.
- X. Cheng et al., "[Extreme Parkour with Legged Robots](https://arxiv.org/abs/2309.14341)," *ICRA*, 2024.

<InteractiveDemo title="Research Frontier">
  <p className="text-sm text-gray-500">
    Explore the latest papers and demos in bipedal locomotion research.
  </p>
</InteractiveDemo>
