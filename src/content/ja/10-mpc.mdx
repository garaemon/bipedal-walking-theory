import { MathBlock } from "@/components/math/MathBlock";
import { CodeEditor } from "@/components/code/CodeEditor";
import { InteractiveDemo } from "@/components/visualization/InteractiveDemo";
import { MPCHorizonDiagram } from "@/components/diagrams/MPCDiagram";

# モデル予測制御 (MPC)

モデル予測制御は、各タイムステップにおいて将来のホライズンにわたって制御入力を最適化し、制約を明示的に扱える歩行のための強力な枠組みを提供します。

## MPCの定式化

各タイムステップ $k$ において、以下の最適化問題を解きます:

<MathBlock tex="\min_{u_0, \ldots, u_{N-1}} \sum_{i=0}^{N-1} \left[ \|\mathbf{x}_i - \mathbf{x}_i^{ref}\|^2_Q + \|u_i\|^2_R \right] + \|\mathbf{x}_N - \mathbf{x}_N^{ref}\|^2_{Q_f}" />

制約条件:
- ダイナミクス: $\mathbf{x}_{i+1} = A\mathbf{x}_i + Bu_i$
- 状態制約: $\mathbf{x}_i \in \mathcal{X}$
- 入力制約: $u_i \in \mathcal{U}$
- ZMP制約: $p_i \in \text{support polygon}$

最初の入力 $u_0^*$ のみを適用し、次のステップで再度解きます。

<MPCHorizonDiagram />

## LIPMを用いた線形MPC

第5章のLIPM状態空間モデルを用いることで、MPCは効率的に解ける**二次計画問題** (QP) となります。

### 状態空間モデル

$$
\mathbf{x}_{k+1} = A\mathbf{x}_k + Bu_k, \quad p_k = C\mathbf{x}_k
$$

ここで $\mathbf{x} = [x, \dot{x}, \ddot{x}]^T$、$u = \dddot{x}$（ジャーク）、$p$ はZMP位置です。

### 二次計画問題の定式化

MPC問題は以下のように書けます:

$$
\min_{\mathbf{U}} \frac{1}{2}\mathbf{U}^T H \mathbf{U} + \mathbf{f}^T \mathbf{U}
$$

制約条件 $A_{ineq}\mathbf{U} \leq \mathbf{b}_{ineq}$

ここで $\mathbf{U} = [u_0, u_1, \ldots, u_{N-1}]^T$ はスタックされた制御入力です。

<CodeEditor
  initialCode={`import math

# Simple Linear MPC for LIPM walking
# Using a basic gradient descent solver (for demonstration)

g = 9.81
z_c = 0.8
T = 0.02  # sampling period
N = 40    # prediction horizon

# LIPM matrices
A = [[1, T, T**2/2], [0, 1, T], [0, 0, 1]]
B = [T**3/6, T**2/2, T]
C = [1, 0, -z_c/g]

def mat_vec_mul(M, v):
    return [sum(M[i][j]*v[j] for j in range(len(v))) for i in range(len(M))]

def predict_trajectory(x0, U):
    """Predict state and ZMP trajectory given control sequence."""
    states = [x0[:]]
    zmps = []
    x = x0[:]
    for u in U:
        zmp = sum(C[j]*x[j] for j in range(3))
        zmps.append(zmp)
        x_new = [sum(A[i][j]*x[j] for j in range(3)) + B[i]*u for i in range(3)]
        states.append(x_new[:])
        x = x_new
    zmps.append(sum(C[j]*x[j] for j in range(3)))
    return states, zmps

# ZMP reference (step pattern in x-direction)
step_duration = 0.6
step_length = 0.15

def get_zmp_ref(t_start, N_steps):
    refs = []
    for i in range(N_steps):
        t = t_start + i * T
        phase = int(t / step_duration)
        refs.append(phase * step_length)
    return refs

# Initial state
x = [0.0, 0.3, 0.0]  # start with forward velocity

# MPC weights
Q_zmp = 1.0    # ZMP tracking weight
R_u = 1e-6     # control effort weight

print("=== Linear MPC Walking ===")
print(f"Horizon: {N} steps ({N*T:.2f}s)")
print(f"Step length: {step_length}m, Step duration: {step_duration}s")
print()

# Simulate for 2 seconds
sim_steps = int(2.0 / T)
print("Time(s)  CoM_x(m)  ZMP(m)   ZMP_ref(m)  Jerk")
print("-" * 55)

for k in range(sim_steps):
    t = k * T
    zmp_ref = get_zmp_ref(t, N + 1)

    # Simple MPC: solve with gradient descent (simplified)
    U = [0.0] * N
    learning_rate = 0.1

    for opt_iter in range(30):
        states, zmps = predict_trajectory(x, U)
        # Gradient of cost w.r.t. U
        grad = [0.0] * N
        for i in range(N):
            zmp_error = zmps[i] - zmp_ref[i]
            grad[i] = 2 * Q_zmp * zmp_error + 2 * R_u * U[i]
        # Update
        for i in range(N):
            U[i] -= learning_rate * grad[i]
            U[i] = max(-50, min(50, U[i]))  # clamp jerk

    # Apply first control input
    u_applied = U[0]
    zmp = sum(C[j]*x[j] for j in range(3))
    phase = int(t / step_duration)
    zmp_ref_now = phase * step_length

    if k % 5 == 0:
        print(f"{t:5.2f}    {x[0]:7.4f}  {zmp:7.4f}   {zmp_ref_now:7.4f}    {u_applied:7.2f}")

    # State update
    x = [sum(A[i][j]*x[j] for j in range(3)) + B[i]*u_applied for i in range(3)]
`}
/>

## 制約の取り扱い

プレビュー制御に対するMPCの主な利点は、明示的な**制約処理**が可能なことです:

### ZMP制約
$$
p_{x,min} \leq C\mathbf{x}_i \leq p_{x,max}
$$

境界値は足のステップタイミング（支持多角形）に応じて変化します。

### 運動学的制約
- 最大ステップ長
- 足のクリアランス高さ
- 関節角度制限

### タイミング適応
MPCはCoM軌道だけでなく、**いつ**ステップを踏むかも最適化できます。これにより、外力に対する反応的なステッピングが可能になります。

## 非線形MPC

より正確な歩行のために、非線形MPCはロボットの完全なダイナミクスを使用します:

$$
\min_{\mathbf{u}(\cdot)} \int_0^T L(\mathbf{x}, \mathbf{u}) dt + V_f(\mathbf{x}(T))
$$

制約条件:
- 完全な非線形ダイナミクス: $\dot{\mathbf{x}} = f(\mathbf{x}, \mathbf{u})$
- 接触相補性: $\lambda \geq 0, \phi(\mathbf{q}) \geq 0, \lambda \phi = 0$

非線形MPCは計算コストが高いですが、以下に対応できます:
- 可変CoM高さ
- 角運動量
- マルチコンタクトシナリオ

## リアルタイム性の考慮

歩行MPCは制御ループ内（約1-10 ms）で解く必要があります。戦略:

1. **ウォームスタート**: 前回の解を初期推定値として使用
2. **早期終了**: 固定反復回数後に準最適解を受け入れる
3. **凝縮定式化**: 状態を消去して問題サイズを削減
4. **専用ソルバー**: 歩行QPのスパース構造を活用

## 参考文献

- P.-B. Wieber, "[Trajectory Free Linear Model Predictive Control for Stable Walking in the Presence of Strong Perturbations](https://doi.org/10.1109/ICHR.2006.321375)," *Proc. IEEE-RAS Humanoids*, 2006.
- A. Herdt et al., "[Online Walking Motion Generation with Automatic Footstep Placement](https://doi.org/10.1163/016918610X12681568462IO)," *Advanced Robotics*, 2010.

<InteractiveDemo title="MPC Horizon Visualization">
  <p className="text-sm text-gray-500">
    Interactive MPC with adjustable horizon and constraints coming soon.
  </p>
</InteractiveDemo>
