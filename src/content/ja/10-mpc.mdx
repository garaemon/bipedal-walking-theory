import { MathBlock } from "@/components/math/MathBlock";
import { CodeEditor } from "@/components/code/CodeEditor";
import { InteractiveDemo } from "@/components/visualization/InteractiveDemo";
import { MPCHorizonDiagram } from "@/components/diagrams/MPCDiagram";
import { MPCConstraintDiagram } from "@/components/diagrams/MPCConstraintDiagram";

# モデル予測制御 (MPC)

モデル予測制御は、各タイムステップにおいて将来のホライズンにわたって制御入力を最適化し、制約を明示的に扱える歩行のための強力な枠組みを提供します。

## MPCの定式化

各タイムステップ $k$ において、以下の最適化問題を解きます:

<MathBlock tex="\min_{u_0, \ldots, u_{N-1}} \sum_{i=0}^{N-1} \left[ \|\mathbf{x}_i - \mathbf{x}_i^{ref}\|^2_Q + \|u_i\|^2_R \right] + \|\mathbf{x}_N - \mathbf{x}_N^{ref}\|^2_{Q_f}" />

制約条件:
- ダイナミクス: $\mathbf{x}_{i+1} = A\mathbf{x}_i + Bu_i$
- 状態制約: $\mathbf{x}_i \in \mathcal{X}$
- 入力制約: $u_i \in \mathcal{U}$
- ZMP制約: $p_i \in \text{support polygon}$

最初の入力 $u_0^*$ のみを適用し、次のステップで再度解きます。

<MPCHorizonDiagram />

### なぜ後退ホライズンなのか？

最初に長いホライズンの問題を一度だけ解いて、その計画をそのまま実行すれば良いのではないでしょうか？ それには3つの重要な理由があります:

1. **モデル誤差**: LIPMは簡略化モデルです。実際のロボットには関節の柔軟性、モデル化されていない摩擦、その他モデルが無視するダイナミクスがあります。小さな誤差が時間とともに蓄積します。
2. **外乱**: 外力による押し、凹凸のある地面、滑りやすい路面などは事前に予測できません。再度解くことで、計測された状態をフィードバックとして取り込めます。
3. **目標の変化**: 歩行中に目標とする歩行パターンが変わることがあります（例：障害物の出現、人間からの新しい指令）。MPCは現在の状態から再計画するため、自然に適応できます。

各タイムステップで最新の計測状態を用いて再度解くことで、MPCはこれらの問題すべてを継続的に修正します。カーナビが出発時に一度だけルートを計算するのではなく、数秒ごとにルートを再計算するのに似ています。

## LIPMを用いた線形MPC

第5章のLIPM状態空間モデルを用いることで、MPCは効率的に解ける**二次計画問題** (QP) となります。

### 状態空間モデル

$$
\mathbf{x}_{k+1} = A\mathbf{x}_k + Bu_k, \quad p_k = C\mathbf{x}_k
$$

ここで $\mathbf{x} = [x, \dot{x}, \ddot{x}]^T$、$u = \dddot{x}$（ジャーク）、$p$ はZMP位置です。

### 二次計画問題の定式化

MPC問題は以下のように書けます:

$$
\min_{\mathbf{U}} \frac{1}{2}\mathbf{U}^T H \mathbf{U} + \mathbf{f}^T \mathbf{U}
$$

制約条件 $A_{ineq}\mathbf{U} \leq \mathbf{b}_{ineq}$

ここで $\mathbf{U} = [u_0, u_1, \ldots, u_{N-1}]^T$ はスタックされた制御入力です。

### 状態空間モデルからQPを構成する方法

行列 $H$ と $\mathbf{f}$ を具体的に求めるため、ダイナミクスを予測ホライズンの $N$ ステップにわたって「展開」します。

**ステップ1: ダイナミクスの積み上げ**
初期状態 $\mathbf{x}_0$ から出発し、すべての将来の状態を初期状態と制御列の関数として書くことができます:

$$
\mathbf{X} = \Phi \mathbf{x}_0 + \Gamma \mathbf{U}
$$

ここで $\mathbf{X} = [\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_N]^T$ は積み上げられた状態ベクトルであり、

$$
\Phi = \begin{bmatrix} A \\ A^2 \\ \vdots \\ A^N \end{bmatrix}, \quad
\Gamma = \begin{bmatrix}
B & 0 & \cdots & 0 \\
AB & B & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
A^{N-1}B & A^{N-2}B & \cdots & B
\end{bmatrix}
$$

$\Phi$ は初期状態を将来に伝播し、$\Gamma$ は制御入力を将来の状態に写す下三角行列です。

**ステップ2: ZMP軌道の予測**
各ステップのZMPは $p_i = C \mathbf{x}_i$ です。すべてのZMP予測を積み上げると:

$$
\mathbf{P} = \bar{C} \mathbf{X} = \bar{C} \Phi \mathbf{x}_0 + \bar{C} \Gamma \mathbf{U}
$$

ここで $\bar{C} = \text{diag}(C, C, \ldots, C)$ はブロック対角行列です。

**ステップ3: コスト関数の構成**
ZMP追従コストは:

$$
J = (\mathbf{P} - \mathbf{P}_{ref})^T Q (\mathbf{P} - \mathbf{P}_{ref}) + \mathbf{U}^T R \mathbf{U}
$$

これを展開して $\mathbf{U}$ の項をまとめると:

$$
H = \Gamma^T \bar{C}^T Q \bar{C} \Gamma + R
$$

$$
\mathbf{f} = \Gamma^T \bar{C}^T Q (\bar{C} \Phi \mathbf{x}_0 - \mathbf{P}_{ref})
$$

**小さな例 (N=3):** サンプリング周期 $T = 0.1$ sの場合、$\Gamma$ の各列は1つの制御入力がすべての将来の状態に与える影響を含みます。例えば、$u_0$ は $B$ を通じて $\mathbf{x}_1$ に、$AB$ を通じて $\mathbf{x}_2$ に、$A^2B$ を通じて $\mathbf{x}_3$ に影響します。一方 $u_2$ は $B$ を通じて $\mathbf{x}_3$ にのみ影響します。この下三角構造が鍵です: 早い時刻の制御入力ほど、予測軌道に大きな影響を持ちます。

## MPC vs. LQR vs. プレビュー制御

MPCが前の章の他のコントローラとどう関係するかを理解すると、各手法をいつ使うべきかが明確になります。

- **LQR**（第4章）は特殊ケースです: 制約なしの無限ホライズンMPCに相当します。LQRはオフラインで計算された固定ゲイン行列 $K$ を生成するため、オンラインでの最適化は不要です。
- **プレビュー制御**（第5章）も特殊ケースです: 将来の参照値のプレビュー窓を持つ無限ホライズン制御ですが、不等式制約はありません。
- **MPCの最大の利点は制約処理です。** ZMPが支持多角形内に留まること、ステップ長が制限内であることなどを明示的に保証できます。
- 制約がアクティブでない場合、MPCとLQRはほぼ同一の制御入力を生成します。制約処理こそが、追加の計算コストに見合うMPCの価値です。

| 特徴 | プレビュー制御 | MPC |
|---|---|---|
| 制約 | なし | あり |
| 計算 | オフラインのゲイン行列 | 各ステップでオンラインQP |
| 最適性 | 無限ホライズン | 有限ホライズン (Nステップ) |
| 反応性 | 限定的（固定ゲイン） | 高い（毎ステップ再計画） |
| 歩行パターンの変更 | オンライン変更不可 | オンラインで適応可能 |

<CodeEditor
  initialCode={`import math
import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
import numpy as np
import io, base64

# Simple Linear MPC for LIPM walking
# Using unconstrained gradient descent (for demonstration only).
#
# Note: This simplified example uses unconstrained gradient descent
# for illustration. In practice, walking MPC uses dedicated QP solvers
# (qpOASES, OSQP, Clarabel) that handle inequality constraints
# efficiently. Typical computation times are 0.1-5 ms per solve,
# allowing control at 100-1000 Hz.

g = 9.81
z_c = 0.8
T = 0.02  # sampling period
N = 40    # prediction horizon

# LIPM matrices
A = [[1, T, T**2/2], [0, 1, T], [0, 0, 1]]
B = [T**3/6, T**2/2, T]
C = [1, 0, -z_c/g]

step_duration = 0.6
step_length = 0.15

def predict_trajectory(x0, U):
    """Predict state and ZMP trajectory given control sequence."""
    states = [x0[:]]
    zmps = []
    x = x0[:]
    for u in U:
        zmp = sum(C[j]*x[j] for j in range(3))
        zmps.append(zmp)
        x_new = [
            sum(A[i][j]*x[j] for j in range(3)) + B[i]*u
            for i in range(3)
        ]
        states.append(x_new[:])
        x = x_new
    zmps.append(sum(C[j]*x[j] for j in range(3)))
    return states, zmps

def get_zmp_ref(t_start, n_steps):
    """Generate ZMP reference based on step pattern."""
    refs = []
    for i in range(n_steps):
        t = t_start + i * T
        phase = int(t / step_duration)
        refs.append(phase * step_length)
    return refs

def compute_support_bounds(t):
    """Return support polygon bounds at time t."""
    phase = int(t / step_duration)
    center = phase * step_length
    half_foot = 0.07
    return center - half_foot, center + half_foot

# Initial state
x = [0.0, 0.3, 0.0]
Q_zmp = 1.0
R_u = 1e-6

print("=== Linear MPC Walking ===")
print("Horizon: {} steps ({:.2f}s)".format(N, N * T))
print("Step length: {}m, Step duration: {}s".format(
    step_length, step_duration))
print()

sim_steps = int(2.0 / T)
print("Time(s)  CoM_x(m)  ZMP(m)   ZMP_ref(m)  Jerk")
print("-" * 55)

# Storage for plotting
time_log = []
com_log = []
zmp_log = []
ref_log = []
jerk_log = []
sp_lo_log = []
sp_hi_log = []

for k in range(sim_steps):
    t = k * T
    zmp_ref = get_zmp_ref(t, N + 1)

    U = [0.0] * N
    lr = 0.1
    for _ in range(30):
        _, zmps = predict_trajectory(x, U)
        grad = [0.0] * N
        for i in range(N):
            err = zmps[i] - zmp_ref[i]
            grad[i] = 2 * Q_zmp * err + 2 * R_u * U[i]
        for i in range(N):
            U[i] -= lr * grad[i]
            U[i] = max(-50, min(50, U[i]))

    u_applied = U[0]
    zmp = sum(C[j] * x[j] for j in range(3))
    zmp_ref_now = int(t / step_duration) * step_length
    lo, hi = compute_support_bounds(t)

    time_log.append(t)
    com_log.append(x[0])
    zmp_log.append(zmp)
    ref_log.append(zmp_ref_now)
    jerk_log.append(u_applied)
    sp_lo_log.append(lo)
    sp_hi_log.append(hi)

    if k % 5 == 0:
        print("{:5.2f}    {:7.4f}  {:7.4f}   {:7.4f}    {:7.2f}".format(
            t, x[0], zmp, zmp_ref_now, u_applied))

    x = [
        sum(A[i][j]*x[j] for j in range(3)) + B[i]*u_applied
        for i in range(3)
    ]

# --- Plot results ---
t_arr = np.array(time_log)
fig, axes = plt.subplots(2, 1, figsize=(8, 6), sharex=True)

ax0 = axes[0]
ax0.fill_between(t_arr, sp_lo_log, sp_hi_log,
                 alpha=0.15, color='gray', label='Support polygon')
ax0.plot(t_arr, com_log, 'b-', linewidth=1.2, label='CoM_x')
ax0.plot(t_arr, zmp_log, 'g-', linewidth=0.8, label='ZMP')
ax0.plot(t_arr, ref_log, 'r--', linewidth=1.0, label='ZMP_ref')
ax0.set_ylabel('Position (m)')
ax0.set_title('Linear MPC Walking: CoM and ZMP Trajectories')
ax0.legend(loc='upper left', fontsize=8)
ax0.grid(True, alpha=0.3)

ax1 = axes[1]
ax1.plot(t_arr, jerk_log, 'm-', linewidth=0.8)
ax1.set_xlabel('Time (s)')
ax1.set_ylabel('Jerk input u (m/s3)')
ax1.set_title('Control Input (Jerk)')
ax1.grid(True, alpha=0.3)
ax1.axhline(y=0, color='k', linewidth=0.5)

plt.tight_layout()
buf = io.BytesIO()
plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
buf.seek(0)
img = base64.b64encode(buf.read()).decode('utf-8')
print('data:image/png;base64,' + img)
plt.close()`}
/>

## シミュレーション: 予測ホライズンの効果

予測ホライズン $N$ はMPCの最も重要なパラメータの一つです。
長いホライズンは将来の参照値の変化（例: 次の足踏み）を予測できますが、計算量が増加します。
以下では同じ歩行シナリオに対して $N=5$、$N=15$、$N=30$ を比較します。

<CodeEditor
  initialCode={`import math
import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
import numpy as np
import io, base64

g = 9.81
z_c = 0.8
T = 0.02
step_duration = 0.6
step_length = 0.15

A = [[1, T, T**2/2], [0, 1, T], [0, 0, 1]]
B = [T**3/6, T**2/2, T]
C = [1, 0, -z_c/g]

def predict_trajectory(x0, U):
    """Predict ZMP trajectory for a given control sequence."""
    zmps = []
    x = x0[:]
    for u in U:
        zmp = sum(C[j]*x[j] for j in range(3))
        zmps.append(zmp)
        x = [
            sum(A[i][j]*x[j] for j in range(3)) + B[i]*u
            for i in range(3)
        ]
    zmps.append(sum(C[j]*x[j] for j in range(3)))
    return zmps

def get_zmp_ref(t_start, n_steps):
    """Generate ZMP reference for the prediction window."""
    refs = []
    for i in range(n_steps):
        t = t_start + i * T
        refs.append(int(t / step_duration) * step_length)
    return refs

def run_mpc_sim(horizon_n):
    """Run a full MPC simulation with a given prediction horizon."""
    x = [0.0, 0.3, 0.0]
    sim_steps = int(2.0 / T)
    Q_zmp = 1.0
    R_u = 1e-6
    lr = 0.1

    t_log, com_log, zmp_log, ref_log = [], [], [], []

    for k in range(sim_steps):
        t = k * T
        zmp_ref = get_zmp_ref(t, horizon_n + 1)

        U = [0.0] * horizon_n
        for _ in range(30):
            zmps = predict_trajectory(x, U)
            grad = [0.0] * horizon_n
            for i in range(horizon_n):
                err = zmps[i] - zmp_ref[i]
                grad[i] = 2*Q_zmp*err + 2*R_u*U[i]
            for i in range(horizon_n):
                U[i] -= lr * grad[i]
                U[i] = max(-50, min(50, U[i]))

        u_applied = U[0]
        zmp = sum(C[j]*x[j] for j in range(3))
        ref_now = int(t / step_duration) * step_length

        t_log.append(t)
        com_log.append(x[0])
        zmp_log.append(zmp)
        ref_log.append(ref_now)

        x = [
            sum(A[i][j]*x[j] for j in range(3)) + B[i]*u_applied
            for i in range(3)
        ]
    return t_log, com_log, zmp_log, ref_log

horizons = [5, 15, 30]
results = {}
for nh in horizons:
    results[nh] = run_mpc_sim(nh)

fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)

for idx, nh in enumerate(horizons):
    t_arr, com_arr, zmp_arr, ref_arr = results[nh]
    t_np = np.array(t_arr)
    zmp_np = np.array(zmp_arr)
    ref_np = np.array(ref_arr)

    tracking_rmse = float(np.sqrt(np.mean((zmp_np - ref_np)**2)))

    ax = axes[idx]
    ax.plot(t_np, com_arr, 'b-', linewidth=1.0, label='CoM_x')
    ax.plot(t_np, zmp_arr, 'g-', linewidth=0.7, label='ZMP')
    ax.plot(t_np, ref_arr, 'r--', linewidth=0.8, label='ZMP_ref')
    ax.set_xlabel('Time (s)')
    if idx == 0:
        ax.set_ylabel('Position (m)')
    ax.set_title('N = {}'.format(nh))
    ax.legend(fontsize=7, loc='upper left')
    ax.grid(True, alpha=0.3)
    ax.annotate('RMSE = {:.4f} m'.format(tracking_rmse),
                xy=(0.98, 0.02), xycoords='axes fraction',
                ha='right', va='bottom', fontsize=8,
                bbox=dict(boxstyle='round,pad=0.3',
                          fc='wheat', alpha=0.7))

fig.suptitle('Effect of Prediction Horizon on MPC Tracking',
             fontsize=13)
plt.tight_layout()
buf = io.BytesIO()
plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
buf.seek(0)
img = base64.b64encode(buf.read()).decode('utf-8')
print('data:image/png;base64,' + img)
plt.close()

print()
print("=== Horizon Comparison Summary ===")
for nh in horizons:
    _, _, zmp_arr, ref_arr = results[nh]
    zmp_np = np.array(zmp_arr)
    ref_np = np.array(ref_arr)
    rmse = float(np.sqrt(np.mean((zmp_np - ref_np)**2)))
    print("N={:2d}  horizon={:.2f}s  ZMP RMSE={:.5f} m".format(
        nh, nh*T, rmse))`}
/>

短いホライズン（$N=5$、先読み0.10秒のみ）では、コントローラは次の足踏み遷移を予測できず、
反応が遅れ、各ステップ変化時に大きな追従誤差が生じます。
中程度のホライズン（$N=15$、0.30秒）では、ステップ変化前にCoMの遷移を開始するのに十分な先読みがあり、
追従性能が大幅に改善されます。
長いホライズン（$N=30$、0.60秒）では1ステップ先まで見通せ、最良の追従を達成しますが、
ある程度を超えると改善は逓減します。

## 制約の取り扱い

プレビュー制御に対するMPCの主な利点は、明示的な**制約処理**が可能なことです:

<MPCConstraintDiagram />

### ZMP制約

$$
p_{x,min} \leq C\mathbf{x}_i \leq p_{x,max}
$$

境界値は足のステップタイミング（支持多角形）に応じて変化します。これらの制約は予測行列を介して $\mathbf{U}$ に対する線形不等式として表現されます:

$$
\bar{C}\Gamma \mathbf{U} \leq \mathbf{b}_{max} - \bar{C}\Phi \mathbf{x}_0, \quad
-\bar{C}\Gamma \mathbf{U} \leq -\mathbf{b}_{min} + \bar{C}\Phi \mathbf{x}_0
$$

### 運動学的制約

- 最大ステップ長
- 足のクリアランス高さ
- 関節角度制限

### タイミング適応

MPCはCoM軌道だけでなく、**いつ**ステップを踏むかも最適化できます。これにより、外力に対する反応的なステッピングが可能になります。

## 非線形MPC

より正確な歩行のために、非線形MPCはロボットの完全なダイナミクスを使用します:

$$
\min_{\mathbf{u}(\cdot)} \int_0^T L(\mathbf{x}, \mathbf{u}) dt + V_f(\mathbf{x}(T))
$$

制約条件:
- 完全な非線形ダイナミクス: $\dot{\mathbf{x}} = f(\mathbf{x}, \mathbf{u})$
- 接触相補性: $\lambda \geq 0, \phi(\mathbf{q}) \geq 0, \lambda \phi = 0$

非線形MPCは計算コストが高いですが、以下に対応できます:
- 可変CoM高さ
- 角運動量
- マルチコンタクトシナリオ

## リアルタイム性の考慮

歩行MPCは制御ループ内（約1-10 ms）で解く必要があります。以下の戦略によりこれが可能になります:

1. **ウォームスタート**: 前回の解を1ステップずらしたものを、現在のQPの初期推定値として使用します。問題は連続するタイムステップ間でわずかしか変化しないため、ずらした解はすでに最適解に近い状態です。これによりソルバーが必要とする反復回数が大幅に減少します。

2. **早期終了**: 固定反復回数後に準最適解を受け入れます。歩行においては、時間内に適用されるわずかに準最適な制御入力の方が、遅れて到着する数学的に最適な入力よりもはるかに有用です。

3. **凝縮定式化**: ダイナミクス制約を代入してすべての状態変数を消去し、QPを $\mathbf{U}$ のみのより小さな問題に縮小します。これはまさに上で導出した $H$、$\mathbf{f}$ の定式化です。密だが小さいQPと、疎だが大きいQPのトレードオフがあります。

4. **専用ソルバー**: 歩行QPは各状態が前の状態にのみ依存するため、帯状（バンド）構造を持ちます。この疎性を活用するソルバー（例: HPIPM）は、反復あたり $O(N^3)$ ではなく $O(N)$ の計算量を達成し、長いホライズンを実現可能にします。

## 参考文献

- P.-B. Wieber, "[Trajectory Free Linear Model Predictive Control for Stable Walking in the Presence of Strong Perturbations](https://doi.org/10.1109/ICHR.2006.321375)," *Proc. IEEE-RAS Humanoids*, 2006.
- A. Herdt et al., "[Online Walking Motion Generation with Automatic Footstep Placement](https://doi.org/10.1163/016918610X12681568462IO)," *Advanced Robotics*, 2010.

<InteractiveDemo title="MPC Horizon Visualization">
  <p className="text-sm text-gray-500">
    Interactive MPC with adjustable horizon and constraints coming soon.
  </p>
</InteractiveDemo>
