import { MathBlock } from "@/components/math/MathBlock";
import { CodeEditor } from "@/components/code/CodeEditor";
import { InteractiveDemo } from "@/components/visualization/InteractiveDemo";
import { PreviewControlDiagram, CoMZMPSystemDiagram } from "@/components/diagrams/PreviewControlDiagram";
import { PreviewGainDiagram } from "@/components/diagrams/PreviewGainDiagram";

# 歩行のためのプレビュー制御

プレビュー制御は、将来の参照情報を利用して歩行パターンを生成する強力な手法です。2003年に梶田らによって二足歩行に導入され、現在も最も広く使用されている手法の一つです。

## 重心-ZMPダイナミクスの状態空間モデル

LIPMの方程式 $\ddot{x} = \frac{g}{z_c}(x - p_x)$ から出発し、ZMPを以下のように表現できます:

$$
p_x = x - \frac{z_c}{g}\ddot{x}
$$

最適制御を適用するために、**躍度** $u = \dddot{x}$ を制御入力として使用します。なぜ加速度や速度ではなく躍度なのでしょうか？その理由は上記のZMP方程式にあります。ZMPは重心の**加速度** $\ddot{x}$ に依存しています。もし加速度を直接制御した場合、制御入力の急激な変化がZMPの不連続なジャンプを引き起こします。**躍度**（加速度の時間微分）を制御することで、加速度が時間的に滑らかに変化し、結果としてZMP軌道も滑らかで連続的になります。これは物理的実現可能性にとって不可欠です。ロボットの足は地面反力を瞬時に変えることができないため、安定した歩行には滑らかなZMP軌道が必要です。

状態ベクトルを $\mathbf{x} = [x, \dot{x}, \ddot{x}]^T$ とすると、離散時間状態空間モデルが得られます:

$$
\mathbf{x}_{k+1} = A\mathbf{x}_k + Bu_k
$$

$$
p_k = C\mathbf{x}_k
$$

ここで（サンプリング周期 $T$ として）:

$$
A = \begin{bmatrix} 1 & T & T^2/2 \\ 0 & 1 & T \\ 0 & 0 & 1 \end{bmatrix}, \quad
B = \begin{bmatrix} T^3/6 \\ T^2/2 \\ T \end{bmatrix}, \quad
C = \begin{bmatrix} 1 & 0 & -z_c/g \end{bmatrix}
$$

<CoMZMPSystemDiagram />

## プレビュー制御理論

鍵となるアイデアは、**将来の参照情報**を利用して追従性能を向上させることです。コントローラは将来の $N_L$ ステップ先まで参照します。

<PreviewControlDiagram />

### コスト関数

プレビューコントローラは以下を最小化します:

$$
J = \sum_{i=k}^{\infty} \left[ Q_e e(i)^2 + R \Delta u(i)^2 \right]
$$

ここで $e(i) = p(i) - p^{ref}(i)$ はZMP追従誤差、$\Delta u(i) = u(i) - u(i-1)$ は制御増分です。

増分型の定式化により、定常状態誤差がゼロになることが保証されます。

### コントローラの構造

最適プレビューコントローラは3つの成分から構成されます:

<MathBlock tex="u(k) = -G_I \sum_{i=0}^{k} e(i) - G_x \mathbf{x}(k) - \sum_{j=1}^{N_L} G_p(j) \, p^{ref}(k+j)" />

1. **積分項** $-G_I \sum e$: 定常状態誤差を除去
2. **状態フィードバック** $-G_x \mathbf{x}$: システムを安定化
3. **プレビュー動作** $-\sum G_p \cdot p^{ref}$: 将来の参照を先読み

プレビューゲイン $G_p(j)$ はプレビューホライズン $j$ とともに減衰するため、近い将来の参照が遠い将来の参照よりも大きな影響を持ちます。

### 直感的な理解

プレビュー制御は車の運転に例えることができます。熟練したドライバーは、タイヤの真下だけを見るのではなく、前方の道路を見てカーブを滑らかに曲がります。

- **プレビューなし**（純粋なフィードバック制御）の場合、重心はZMP参照が変化した**後に**反応します。これは車のタイヤの真下だけを見て運転するようなものです。結果として、各ステップ遷移時に大きなオーバーシュートを伴う不安定な追従になります。
- **プレビューあり**の場合、コントローラはZMP参照がどこに向かうかを事前に知っているため、ステップ遷移が発生する**前に**重心が重心移動を開始します。これにより滑らかで自然な動きが生まれます。
- プレビュー窓は通常**1.5〜2秒**（約2〜3歩先）をカバーします。それ以上先を見ても、プレビューゲイン $G_p(j)$ が指数的に減衰するため、効果は限定的です。

## プレビューゲインの計算

ゲインは**離散時間代数リカッチ方程式** (DARE) を解くことで得られます:

$$
P = A_e^T P A_e - A_e^T P B_e (R + B_e^T P B_e)^{-1} B_e^T P A_e + C_e^T Q_e C_e
$$

ここで $A_e$、$B_e$、$C_e$ は積分器の状態を含む**拡大システム行列**です。拡大状態ベクトルは $\mathbf{x}_e = [\varepsilon, \Delta x, \Delta \dot{x}, \Delta \ddot{x}]^T$ であり、$\varepsilon$ は累積ZMP誤差（積分項）を追跡し、$\Delta$ は前の時刻ステップからの増分を表します（例：$\Delta x = x_k - x_{k-1}$）。拡大行列は以下のようになります:

$$
A_e = \begin{bmatrix} 1 & C A \\ \mathbf{0} & A \end{bmatrix}
= \begin{bmatrix}
1 & 1 & T & T^2/2 - z_c/g \\
0 & 1 & T & T^2/2 \\
0 & 0 & 1 & T \\
0 & 0 & 0 & 1
\end{bmatrix}
$$

$$
B_e = \begin{bmatrix} CB \\ B \end{bmatrix}
= \begin{bmatrix}
T^3/6 - z_cT/g \\
T^3/6 \\
T^2/2 \\
T
\end{bmatrix}, \quad
C_e = \begin{bmatrix} 1 & 0 & 0 & 0 \end{bmatrix}
$$

$A_e$ の一番上の行は出力方程式 $p = C\mathbf{x}$ を使ってZMP誤差積分を伝搬し、下のブロックは元のLIPMダイナミクスを増分形式で伝搬します。この拡大定式化こそが、積分動作を通じてゼロ定常状態追従誤差を保証するものです。

<PreviewGainDiagram />

<CodeEditor
  initialCode={`import math
import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
import numpy as np
import io, base64

# Preview control gain computation (simplified)
# Using the LIPM state-space model

g = 9.81
z_c = 0.8
T = 0.01  # sampling period (s)
N_preview = 160  # preview steps (1.6 seconds ahead)

# State-space matrices
A = [
    [1, T, T**2/2],
    [0, 1, T],
    [0, 0, 1]
]
B = [T**3/6, T**2/2, T]
C = [1, 0, -z_c/g]

# Compute ZMP output: p = C * x
def compute_zmp(x):
    return C[0]*x[0] + C[1]*x[1] + C[2]*x[2]

# Simple preview control simulation
# (using pre-computed approximate gains for demonstration)
Gi = 1200.0  # integral gain
Gx = [8e5, 7e3, 30.0]  # state feedback gains

# ZMP reference: step between left and right foot
step_duration = 0.6  # seconds
step_width = 0.04  # lateral step (m)

print("=== Preview Control Walking Simulation ===")
print(f"Preview horizon: {N_preview * T:.2f} s ({N_preview} steps)")
print(f"Step duration: {step_duration} s")
print()

# State: [y, ydot, yddot] (lateral direction)
x = [0.0, 0.0, 0.0]
integral_error = 0.0
sim_time = 3.0
steps_sim = int(sim_time / T)

# Store data for plotting
time_data = []
com_y_data = []
zmp_y_data = []
zmp_ref_y_data = []

print("Time(s)  CoM_y(mm)  ZMP_y(mm)  ZMP_ref(mm)")
print("-" * 50)

for k in range(steps_sim):
    t = k * T
    # ZMP reference (alternating between feet)
    phase = int(t / step_duration)
    zmp_ref = step_width if phase % 2 == 0 else -step_width

    # Current ZMP
    p = compute_zmp(x)

    # Tracking error
    e = p - zmp_ref
    integral_error += e

    # Control input (simplified - without full preview sum)
    u = -Gi * integral_error * T
    u -= Gx[0]*x[0] + Gx[1]*x[1] + Gx[2]*x[2]

    # State update
    x_new = [
        A[0][0]*x[0] + A[0][1]*x[1] + A[0][2]*x[2] + B[0]*u,
        A[1][0]*x[0] + A[1][1]*x[1] + A[1][2]*x[2] + B[1]*u,
        A[2][0]*x[0] + A[2][1]*x[1] + A[2][2]*x[2] + B[2]*u,
    ]
    x = x_new

    # Record data
    time_data.append(t)
    com_y_data.append(x[0] * 1000)
    zmp_y_data.append(p * 1000)
    zmp_ref_y_data.append(zmp_ref * 1000)

    if k % 50 == 0:
        print(f"{t:5.2f}    {x[0]*1000:8.2f}   {p*1000:8.2f}    {zmp_ref*1000:8.2f}")

print()
print("Note: Full preview control uses future ZMP reference")
print("values for better anticipation and smoother tracking.")

# Plot CoM and ZMP trajectories
time_arr = np.array(time_data)
com_arr = np.array(com_y_data)
zmp_arr = np.array(zmp_y_data)
ref_arr = np.array(zmp_ref_y_data)

fig, axes = plt.subplots(2, 1, figsize=(8, 6))

axes[0].plot(time_arr, com_arr, 'b-', label='CoM_y')
axes[0].plot(time_arr, ref_arr, 'r--', label='ZMP_ref_y')
axes[0].set_xlabel('Time (s)')
axes[0].set_ylabel('Position (mm)')
axes[0].set_title('Lateral Preview Control: CoM vs ZMP Reference')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

tracking_error = zmp_arr - ref_arr
axes[1].plot(time_arr, tracking_error, 'g-', linewidth=1)
axes[1].set_xlabel('Time (s)')
axes[1].set_ylabel('Error (mm)')
axes[1].set_title('ZMP Tracking Error (ZMP_y - ZMP_ref_y)')
axes[1].grid(True, alpha=0.3)
axes[1].axhline(y=0, color='k', linewidth=0.5)

plt.tight_layout()
buf = io.BytesIO()
plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
buf.seek(0)
img = base64.b64encode(buf.read()).decode('utf-8')
print(f'data:image/png;base64,{img}')
plt.close()
`}
/>

上記で使用したゲイン（`Gi = 1200`、`Gx = [8e5, 7e3, 30]`）は、重みパラメータ $Q_e = 1.0$ および $R = 1 \times 10^{-6}$ でDAREを解くことで得られます。$Q_e / R$ の比率が大きい（$10^6$ のオーダー）ということは、制御労力の最小化よりもZMP追従精度を強く優先していることを意味します。実際には、躍度入力のコストは小さいため、このトレードオフは適切です。プレビューゲイン $G_p(j)$ は $j$ に対して指数的に減衰します。遠い将来の参照は現在の制御入力にほとんど影響を与えず、次の数ステップが支配的です。これは直感と一致しています：2秒後に何が起こるかよりも、次の0.1秒間に何が起こるかの方がはるかに重要です。

## 歩行パターン生成パイプライン

ZMPベースの歩行のための完全なパイプライン:

1. **足踏み計画**: 各ステップの位置とタイミングを定義
2. **ZMP参照生成**: 支持多角形内に収まる区分定数ZMP軌道を作成
3. **プレビュー制御**: ZMP参照を追従する重心軌道を計算
4. **逆運動学**: 重心＋足軌道を関節角度に変換

<CodeEditor
  initialCode={`import math
import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
import numpy as np
import io, base64

# Walking pattern generation with preview control
g = 9.81
z_c = 0.8
omega = math.sqrt(g / z_c)
T = 0.01

# Footstep plan (x, y positions of each step)
footsteps = [
    (0.00, 0.05),   # left foot
    (0.20, -0.05),  # right foot
    (0.40, 0.05),   # left foot
    (0.60, -0.05),  # right foot
    (0.80, 0.05),   # left foot (final)
]
step_duration = 0.6  # seconds per step

print("=== Footstep Plan ===")
for i, (fx, fy) in enumerate(footsteps):
    side = "L" if i % 2 == 0 else "R"
    print(f"  Step {i} ({side}): x={fx:.2f}m, y={fy:+.2f}m")

# Generate ZMP reference (sagittal direction)
total_time = len(footsteps) * step_duration
n_steps = int(total_time / T)

print(f"\\nTotal walking time: {total_time:.1f} s")
print(f"Simulation steps: {n_steps}")
print()

# ZMP reference for sagittal (x) direction
zmp_ref_x = []
for k in range(n_steps):
    t = k * T
    phase = min(int(t / step_duration), len(footsteps) - 1)
    zmp_ref_x.append(footsteps[phase][0])

# Simple forward simulation to show CoM tracking
x = [0.0, 0.2, 0.0]  # [position, velocity, acceleration]
C = [1, 0, -z_c/g]

print("Time(s)  CoM_x(m)  ZMP(m)   ZMP_ref(m)  Error(mm)")
print("-" * 55)

integral_e = 0.0
Gi, Gx0, Gx1, Gx2 = 800, 5e5, 5e3, 25

# Initialize data storage for plotting
time_data = []
com_x_data = []
zmp_ref_x_data = []

for k in range(n_steps):
    t = k * T
    p = C[0]*x[0] + C[1]*x[1] + C[2]*x[2]
    e = p - zmp_ref_x[k]
    integral_e += e

    u = -Gi*integral_e*T - Gx0*x[0] - Gx1*x[1] - Gx2*x[2]
    x = [
        x[0] + T*x[1] + T**2/2*x[2] + T**3/6*u,
        x[1] + T*x[2] + T**2/2*u,
        x[2] + T*u,
    ]

    time_data.append(t)
    com_x_data.append(x[0])
    zmp_ref_x_data.append(zmp_ref_x[k])

    if k % 60 == 0:
        print(f"{t:5.2f}    {x[0]:7.4f}   {p:7.4f}   {zmp_ref_x[k]:7.4f}    {e*1000:+6.2f}")

# Plot sagittal CoM vs ZMP reference
fig, ax = plt.subplots(1, 1, figsize=(8, 4))
time_arr = np.array(time_data)
ax.plot(time_arr, com_x_data, 'b-', label='CoM_x')
ax.plot(time_arr, zmp_ref_x_data, 'r--', label='ZMP_ref_x')
ax.set_xlabel('Time (s)')
ax.set_ylabel('Position (m)')
ax.set_title('Sagittal Walking Pattern: CoM vs ZMP Reference')
ax.legend()
ax.grid(True, alpha=0.3)

plt.tight_layout()
buf = io.BytesIO()
plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
buf.seek(0)
img = base64.b64encode(buf.read()).decode('utf-8')
print(f'data:image/png;base64,{img}')
plt.close()
`}
/>

## \u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3: \u30d7\u30ec\u30d3\u30e5\u30fc\u30b2\u30a4\u30f3\u5206\u6790

\u30d7\u30ec\u30d3\u30e5\u30fc\u30b2\u30a4\u30f3 $G_p(j)$ \u306f\u3001\u5404\u5c06\u6765\u53c2\u7167\u30b9\u30c6\u30c3\u30d7\u304c\u73fe\u5728\u306e\u5236\u5fa1\u5165\u529b\u306b\u3069\u308c\u3060\u3051\u5f71\u97ff\u3059\u308b\u304b\u3092\u6c7a\u5b9a\u3057\u307e\u3059\u3002$j$ \u304c\u5897\u52a0\u3059\u308b\u3068\u30b2\u30a4\u30f3\u306f\u6e1b\u8870\u3057\u3001\u9060\u3044\u5c06\u6765\u306e\u53c2\u7167\u306e\u5bc4\u4e0e\u304c\u5c0f\u3055\u304f\u306a\u308a\u307e\u3059\u3002\u4ee5\u4e0b\u306e\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u306f\u3001\u7570\u306a\u308b\u30d7\u30ec\u30d3\u30e5\u30fc\u30db\u30e9\u30a4\u30ba\u30f3\u9577\u306b\u5bfe\u3057\u3066\u3053\u308c\u3089\u306e\u30b2\u30a4\u30f3\u3092\u8a08\u7b97\u30fb\u53ef\u8996\u5316\u3057\u307e\u3059\u3002

<CodeEditor
  initialCode={`import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
import numpy as np
import io, base64

g = 9.81
z_c = 0.8
T = 0.01
Qe = 1.0
R = 1e-6

def build_augmented_system(T, z_c, g):
    """Build augmented state-space matrices for preview control."""
    A = np.array([
        [1, T, T**2/2],
        [0, 1, T],
        [0, 0, 1]
    ])
    B = np.array([[T**3/6], [T**2/2], [T]])
    C = np.array([[1, 0, -z_c/g]])
    Ae = np.zeros((4, 4))
    Ae[0, 0] = 1
    Ae[0, 1:] = (C @ A).flatten()
    Ae[1:, 1:] = A
    Be = np.zeros((4, 1))
    Be[0, 0] = (C @ B).item()
    Be[1:, :] = B
    Ce = np.array([[1, 0, 0, 0]])
    return Ae, Be, Ce

def solve_dare_iterative(Ae, Be, Ce, Qe_val, R_val, n_iter=5000):
    """Solve DARE by iterating the Riccati recursion."""
    n = Ae.shape[0]
    P = np.eye(n) * 0.001
    Q_mat = Ce.T @ (Qe_val * np.eye(1)) @ Ce
    for _ in range(n_iter):
        S = R_val + (Be.T @ P @ Be).item()
        K = (Be.T @ P @ Ae) / S
        P_new = Ae.T @ P @ Ae - Ae.T @ P @ Be @ K + Q_mat
        if np.max(np.abs(P_new - P)) < 1e-12:
            break
        P = P_new
    return P

def compute_preview_gains(Ae, Be, P, R_val, N):
    """Compute preview gains Gp(j) for j = 0, ..., N-1."""
    S = R_val + (Be.T @ P @ Be).item()
    K_fb = (Be.T @ P @ Ae) / S
    Acl = Ae - Be @ K_fb
    gains = np.zeros(N)
    Fj = np.eye(Ae.shape[0])
    for j in range(N):
        vec = Fj.T @ P @ np.array([[1], [0], [0], [0]])
        gains[j] = (Be.T @ vec).item() / S
        Fj = Fj @ Acl
    return gains

Ae, Be, Ce = build_augmented_system(T, z_c, g)
P = solve_dare_iterative(Ae, Be, Ce, Qe, R)

horizon_list = [50, 100, 160]
colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
labels = []
for nh in horizon_list:
    labels.append(f"N={nh} ({nh*T:.1f}s)")

fig, axes = plt.subplots(2, 1, figsize=(8, 6))

for idx, N_h in enumerate(horizon_list):
    gp = compute_preview_gains(Ae, Be, P, R, N_h)
    j_arr = np.arange(N_h)
    t_arr = j_arr * T
    markerline, stemlines, baseline = axes[0].stem(
        t_arr, gp, linefmt=colors[idx],
        markerfmt='o', basefmt='k-', label=labels[idx]
    )
    markerline.set_markersize(2)
    stemlines.set_linewidth(0.8)

    gp_normalized = gp / np.max(np.abs(gp)) if np.max(np.abs(gp)) > 0 else gp
    axes[1].plot(t_arr, gp_normalized, color=colors[idx],
                 linewidth=1.5, label=labels[idx])

axes[0].set_xlabel('Preview time j*T (s)')
axes[0].set_ylabel('Preview gain Gp(j)')
axes[0].set_title('Preview Gains: Decay with Horizon')
axes[0].legend(fontsize=8)
axes[0].grid(True, alpha=0.3)

axes[1].set_xlabel('Preview time j*T (s)')
axes[1].set_ylabel('Normalized Gp(j)')
axes[1].set_title('Normalized Preview Gains')
axes[1].legend(fontsize=8)
axes[1].grid(True, alpha=0.3)
axes[1].axhline(y=0, color='k', linewidth=0.5)

plt.tight_layout()
buf = io.BytesIO()
plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
buf.seek(0)
img = base64.b64encode(buf.read()).decode('utf-8')
print(f'data:image/png;base64,{img}')
plt.close()

print("=== Preview Gain Analysis ===")
for idx, N_h in enumerate(horizon_list):
    gp = compute_preview_gains(Ae, Be, P, R, N_h)
    peak = np.max(np.abs(gp))
    last = np.abs(gp[-1])
    ratio = last / peak if peak > 0 else 0
    print(f"N={N_h:3d} ({N_h*T:.1f}s): peak=|Gp|={peak:.4e}, "
          f"last=|Gp(N-1)|={last:.4e}, ratio={ratio:.4e}")
print()
print("The rapid decay confirms that distant future references")
print("contribute negligibly to the current control input.")
`}
/>

## モデル予測制御（MPC）との比較

プレビュー制御とMPC（第10章で解説）はどちらも将来の参照情報を使用しますが、制御入力の計算方法が根本的に異なります:

| 観点 | プレビュー制御 | MPC |
|------|--------------|-----|
| **最適化** | 無限ホライズンLQRを**オフライン**で解く | 有限ホライズンQPを各ステップで**オンライン**で解く |
| **ゲイン** | 一度事前計算し、ルックアップとして適用 | 毎制御サイクルで再計算 |
| **速度** | 実行時に非常に高速（乗算と和のみ） | 遅い（最適化問題を解く必要あり） |
| **制約** | 制約を課すことができない（ZMP境界など） | ZMPやアクチュエータの制約を明示的に課せる |
| **柔軟性** | 固定の線形モデルのみ | 非線形モデルも組み込み可能 |

本質的に、プレビュー制御は事前計算された閉形式解を持つ**制約なしMPC**と見なすことができます。制約がアクティブでない場合（例えば、ZMP参照が支持多角形の内部に十分収まっている場合）、両方の手法はほぼ同一の結果を生成します。ロボットが物理的限界に近い状態で歩行する必要がある場合や、予期しない外乱に対処する必要がある場合に、MPCが必要になります。

## 利点と限界

**利点:**
- 滑らかな重心軌道を生成
- 解析的に導出された最適ゲイン
- 計算効率が高い（ゲインはオフラインで計算）
- 平坦地形の歩行に適している

**限界:**
- 線形モデルのみ（重心高さ一定）
- 固定のプレビューホライズン
- 大きな外乱にオンラインで対応できない
- 事前に計画された足踏みを前提とする

## 参考文献

- S. Kajita et al., "[Biped Walking Pattern Generation by using Preview Control of Zero-Moment Point](https://doi.org/10.1109/ROBOT.2003.1241826)," *Proc. IEEE ICRA*, 2003.
- T. Katayama et al., "[Design of an optimal controller for a discrete-time system subject to previewable demand](https://doi.org/10.1080/0020718508961156)," *Int. J. Control*, 1985.

<InteractiveDemo title="Preview Control Visualization">
  <p className="text-sm text-gray-500">
    Interactive preview control with adjustable preview window coming soon.
  </p>
</InteractiveDemo>
