import { MathBlock } from "@/components/math/MathBlock";
import { CodeEditor } from "@/components/code/CodeEditor";
import { InteractiveDemo } from "@/components/visualization/InteractiveDemo";
import { PreviewControlDiagram, CoMZMPSystemDiagram } from "@/components/diagrams/PreviewControlDiagram";
import { PreviewGainDiagram } from "@/components/diagrams/PreviewGainDiagram";

# Preview Control for Walking

Preview control is a powerful technique for generating walking patterns by
using future reference information. It was introduced to bipedal walking by
Kajita et al. in 2003 and remains one of the most widely used methods.

## State-Space Model of CoM-ZMP Dynamics

Starting from the LIPM equation $\ddot{x} = \frac{g}{z_c}(x - p_x)$,
we can express the ZMP as:

$$
p_x = x - \frac{z_c}{g}\ddot{x}
$$

To apply optimal control, we use the **jerk** $u = \dddot{x}$ as the control
input. Why jerk, rather than acceleration or velocity? The key reason lies
in the ZMP equation above: the ZMP depends on the CoM **acceleration**
$\ddot{x}$. If we controlled the acceleration directly, any sudden change
in the control input would cause the ZMP to jump discontinuously. By
controlling the **jerk** (the time derivative of acceleration), we ensure
that acceleration changes smoothly over time, which in turn makes the ZMP
trajectory smooth and continuous. This is essential for physical
realizability: a robot's feet cannot instantaneously change the ground
reaction force, so smooth ZMP trajectories are required for stable walking.

The state vector is $\mathbf{x} = [x, \dot{x}, \ddot{x}]^T$, giving
the discrete-time state-space model:

$$
\mathbf{x}_{k+1} = A\mathbf{x}_k + Bu_k
$$

$$
p_k = C\mathbf{x}_k
$$

where (with sampling period $T$):

$$
A = \begin{bmatrix} 1 & T & T^2/2 \\ 0 & 1 & T \\ 0 & 0 & 1 \end{bmatrix}, \quad
B = \begin{bmatrix} T^3/6 \\ T^2/2 \\ T \end{bmatrix}, \quad
C = \begin{bmatrix} 1 & 0 & -z_c/g \end{bmatrix}
$$

<CoMZMPSystemDiagram />

## Preview Control Theory

The key idea is to use **future reference information** to improve tracking
performance. The controller looks ahead $N_L$ steps into the future.

<PreviewControlDiagram />

### Cost Function

The preview controller minimizes:

$$
J = \sum_{i=k}^{\infty} \left[ Q_e e(i)^2 + R \Delta u(i)^2 \right]
$$

where $e(i) = p(i) - p^{ref}(i)$ is the ZMP tracking error and
$\Delta u(i) = u(i) - u(i-1)$ is the control increment.

The incremental formulation ensures zero steady-state error.

### Controller Structure

The optimal preview controller has three components:

<MathBlock tex="u(k) = -G_I \sum_{i=0}^{k} e(i) - G_x \mathbf{x}(k) - \sum_{j=1}^{N_L} G_p(j) \, p^{ref}(k+j)" />

1. **Integral term** $-G_I \sum e$: eliminates steady-state error
2. **State feedback** $-G_x \mathbf{x}$: stabilizes the system
3. **Preview action** $-\sum G_p \cdot p^{ref}$: anticipates future reference

The preview gains $G_p(j)$ decay with preview horizon $j$, meaning
near-future references have more influence than distant ones.

### Intuitive Understanding

Preview control is analogous to driving a car: a skilled driver looks
ahead at the road to steer smoothly through curves, rather than reacting
only to what is directly under the wheels.

- **Without preview** (pure feedback control), the CoM reacts **after** the
  ZMP reference changes. This is like driving by only looking at the road
  directly beneath the car. The result is jerky, delayed tracking with
  large overshoot at each step transition.
- **With preview**, the CoM starts shifting weight **before** a step
  transition occurs, because the controller already knows where the ZMP
  reference is heading. This produces smooth, natural-looking motion.
- The preview window typically covers **1.5 to 2 seconds** (about 2-3
  steps ahead). Looking further ahead gives diminishing returns because the
  preview gains $G_p(j)$ decay exponentially.

## Computing Preview Gains

The gains are obtained by solving the **discrete-time algebraic Riccati equation** (DARE):

$$
P = A_e^T P A_e - A_e^T P B_e (R + B_e^T P B_e)^{-1} B_e^T P A_e + C_e^T Q_e C_e
$$

where $A_e$, $B_e$, $C_e$ are the **augmented system matrices** that include
the integrator state. The augmented state vector is
$\mathbf{x}_e = [\varepsilon, \Delta x, \Delta \dot{x}, \Delta \ddot{x}]^T$,
where $\varepsilon$ tracks the cumulative ZMP error (the integral term) and
$\Delta$ denotes the increment from the previous time step
(e.g., $\Delta x = x_k - x_{k-1}$). The augmented matrices are:

$$
A_e = \begin{bmatrix} 1 & C A \\ \mathbf{0} & A \end{bmatrix}
= \begin{bmatrix}
1 & 1 & T & T^2/2 - z_c/g \\
0 & 1 & T & T^2/2 \\
0 & 0 & 1 & T \\
0 & 0 & 0 & 1
\end{bmatrix}
$$

$$
B_e = \begin{bmatrix} CB \\ B \end{bmatrix}
= \begin{bmatrix}
T^3/6 - z_cT/g \\
T^3/6 \\
T^2/2 \\
T
\end{bmatrix}, \quad
C_e = \begin{bmatrix} 1 & 0 & 0 & 0 \end{bmatrix}
$$

The top row of $A_e$ propagates the ZMP error integral using the output
equation $p = C\mathbf{x}$, while the lower block propagates the original
LIPM dynamics in incremental form. This augmented formulation is what
guarantees zero steady-state tracking error through the integral action.

<PreviewGainDiagram />

<CodeEditor
  initialCode={`import math
import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
import numpy as np
import io, base64

# Preview control gain computation (simplified)
# Using the LIPM state-space model

g = 9.81
z_c = 0.8
T = 0.01  # sampling period (s)
N_preview = 160  # preview steps (1.6 seconds ahead)

# State-space matrices
A = [
    [1, T, T**2/2],
    [0, 1, T],
    [0, 0, 1]
]
B = [T**3/6, T**2/2, T]
C = [1, 0, -z_c/g]

# Compute ZMP output: p = C * x
def compute_zmp(x):
    return C[0]*x[0] + C[1]*x[1] + C[2]*x[2]

# Simple preview control simulation
# (using pre-computed approximate gains for demonstration)
Gi = 1200.0  # integral gain
Gx = [8e5, 7e3, 30.0]  # state feedback gains

# ZMP reference: step between left and right foot
step_duration = 0.6  # seconds
step_width = 0.04  # lateral step (m)

print("=== Preview Control Walking Simulation ===")
print(f"Preview horizon: {N_preview * T:.2f} s ({N_preview} steps)")
print(f"Step duration: {step_duration} s")
print()

# State: [y, ydot, yddot] (lateral direction)
x = [0.0, 0.0, 0.0]
integral_error = 0.0
sim_time = 3.0
steps_sim = int(sim_time / T)

# Store data for plotting
time_data = []
com_y_data = []
zmp_y_data = []
zmp_ref_y_data = []

print("Time(s)  CoM_y(mm)  ZMP_y(mm)  ZMP_ref(mm)")
print("-" * 50)

for k in range(steps_sim):
    t = k * T
    # ZMP reference (alternating between feet)
    phase = int(t / step_duration)
    zmp_ref = step_width if phase % 2 == 0 else -step_width

    # Current ZMP
    p = compute_zmp(x)

    # Tracking error
    e = p - zmp_ref
    integral_error += e

    # Control input (simplified - without full preview sum)
    u = -Gi * integral_error * T
    u -= Gx[0]*x[0] + Gx[1]*x[1] + Gx[2]*x[2]

    # State update
    x_new = [
        A[0][0]*x[0] + A[0][1]*x[1] + A[0][2]*x[2] + B[0]*u,
        A[1][0]*x[0] + A[1][1]*x[1] + A[1][2]*x[2] + B[1]*u,
        A[2][0]*x[0] + A[2][1]*x[1] + A[2][2]*x[2] + B[2]*u,
    ]
    x = x_new

    # Record data
    time_data.append(t)
    com_y_data.append(x[0] * 1000)
    zmp_y_data.append(p * 1000)
    zmp_ref_y_data.append(zmp_ref * 1000)

    if k % 50 == 0:
        print(f"{t:5.2f}    {x[0]*1000:8.2f}   {p*1000:8.2f}    {zmp_ref*1000:8.2f}")

print()
print("Note: Full preview control uses future ZMP reference")
print("values for better anticipation and smoother tracking.")

# Plot CoM and ZMP trajectories
time_arr = np.array(time_data)
com_arr = np.array(com_y_data)
zmp_arr = np.array(zmp_y_data)
ref_arr = np.array(zmp_ref_y_data)

fig, axes = plt.subplots(2, 1, figsize=(8, 6))

axes[0].plot(time_arr, com_arr, 'b-', label='CoM_y')
axes[0].plot(time_arr, ref_arr, 'r--', label='ZMP_ref_y')
axes[0].set_xlabel('Time (s)')
axes[0].set_ylabel('Position (mm)')
axes[0].set_title('Lateral Preview Control: CoM vs ZMP Reference')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

tracking_error = zmp_arr - ref_arr
axes[1].plot(time_arr, tracking_error, 'g-', linewidth=1)
axes[1].set_xlabel('Time (s)')
axes[1].set_ylabel('Error (mm)')
axes[1].set_title('ZMP Tracking Error (ZMP_y - ZMP_ref_y)')
axes[1].grid(True, alpha=0.3)
axes[1].axhline(y=0, color='k', linewidth=0.5)

plt.tight_layout()
buf = io.BytesIO()
plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
buf.seek(0)
img = base64.b64encode(buf.read()).decode('utf-8')
print(f'data:image/png;base64,{img}')
plt.close()
`}
/>

The gains used above (`Gi = 1200`, `Gx = [8e5, 7e3, 30]`) come from
solving the DARE with weight parameters $Q_e = 1.0$ and $R = 1 \times 10^{-6}$.
The large $Q_e / R$ ratio (on the order of $10^6$) means we strongly
prioritize ZMP tracking accuracy over minimizing control effort. In
practice, the jerk input is cheap to produce, so this trade-off is
appropriate. The preview gains $G_p(j)$ decay exponentially with $j$:
references far in the future barely affect the current control input, while
the next few steps dominate. This is consistent with intuition: what
happens 2 seconds from now matters much less than what happens in the next
0.1 seconds.

## Walking Pattern Generation Pipeline

The complete pipeline for ZMP-based walking:

1. **Footstep planning**: Define positions and timing of each step
2. **ZMP reference generation**: Create a piecewise-constant ZMP trajectory
   that stays within support polygons
3. **Preview control**: Compute CoM trajectory that tracks the ZMP reference
4. **Inverse kinematics**: Convert CoM + foot trajectories to joint angles

<CodeEditor
  initialCode={`import math
import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
import numpy as np
import io, base64

# Walking pattern generation with preview control
g = 9.81
z_c = 0.8
omega = math.sqrt(g / z_c)
T = 0.01

# Footstep plan (x, y positions of each step)
footsteps = [
    (0.00, 0.05),   # left foot
    (0.20, -0.05),  # right foot
    (0.40, 0.05),   # left foot
    (0.60, -0.05),  # right foot
    (0.80, 0.05),   # left foot (final)
]
step_duration = 0.6  # seconds per step

print("=== Footstep Plan ===")
for i, (fx, fy) in enumerate(footsteps):
    side = "L" if i % 2 == 0 else "R"
    print(f"  Step {i} ({side}): x={fx:.2f}m, y={fy:+.2f}m")

# Generate ZMP reference (sagittal direction)
total_time = len(footsteps) * step_duration
n_steps = int(total_time / T)

print(f"\\nTotal walking time: {total_time:.1f} s")
print(f"Simulation steps: {n_steps}")
print()

# ZMP reference for sagittal (x) direction
zmp_ref_x = []
for k in range(n_steps):
    t = k * T
    phase = min(int(t / step_duration), len(footsteps) - 1)
    zmp_ref_x.append(footsteps[phase][0])

# Simple forward simulation to show CoM tracking
x = [0.0, 0.2, 0.0]  # [position, velocity, acceleration]
C = [1, 0, -z_c/g]

print("Time(s)  CoM_x(m)  ZMP(m)   ZMP_ref(m)  Error(mm)")
print("-" * 55)

integral_e = 0.0
Gi, Gx0, Gx1, Gx2 = 800, 5e5, 5e3, 25

# Initialize data storage for plotting
time_data = []
com_x_data = []
zmp_ref_x_data = []

for k in range(n_steps):
    t = k * T
    p = C[0]*x[0] + C[1]*x[1] + C[2]*x[2]
    e = p - zmp_ref_x[k]
    integral_e += e

    u = -Gi*integral_e*T - Gx0*x[0] - Gx1*x[1] - Gx2*x[2]
    x = [
        x[0] + T*x[1] + T**2/2*x[2] + T**3/6*u,
        x[1] + T*x[2] + T**2/2*u,
        x[2] + T*u,
    ]

    time_data.append(t)
    com_x_data.append(x[0])
    zmp_ref_x_data.append(zmp_ref_x[k])

    if k % 60 == 0:
        print(f"{t:5.2f}    {x[0]:7.4f}   {p:7.4f}   {zmp_ref_x[k]:7.4f}    {e*1000:+6.2f}")

# Plot sagittal CoM vs ZMP reference
fig, ax = plt.subplots(1, 1, figsize=(8, 4))
time_arr = np.array(time_data)
ax.plot(time_arr, com_x_data, 'b-', label='CoM_x')
ax.plot(time_arr, zmp_ref_x_data, 'r--', label='ZMP_ref_x')
ax.set_xlabel('Time (s)')
ax.set_ylabel('Position (m)')
ax.set_title('Sagittal Walking Pattern: CoM vs ZMP Reference')
ax.legend()
ax.grid(True, alpha=0.3)

plt.tight_layout()
buf = io.BytesIO()
plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
buf.seek(0)
img = base64.b64encode(buf.read()).decode('utf-8')
print(f'data:image/png;base64,{img}')
plt.close()
`}
/>

## Simulation: Preview Gain Analysis

The preview gains $G_p(j)$ determine how much each future reference step
influences the current control input. As $j$ increases, the gains decay,
meaning distant future references contribute less. The following simulation
computes and visualizes these gains for different preview horizon lengths.

<CodeEditor
  initialCode={`import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
import numpy as np
import io, base64

g = 9.81
z_c = 0.8
T = 0.01
Qe = 1.0
R = 1e-6

def build_augmented_system(T, z_c, g):
    """Build augmented state-space matrices for preview control."""
    # Original system matrices
    A = np.array([
        [1, T, T**2/2],
        [0, 1, T],
        [0, 0, 1]
    ])
    B = np.array([[T**3/6], [T**2/2], [T]])
    C = np.array([[1, 0, -z_c/g]])
    # Augmented system (integrator + original state in incremental form)
    Ae = np.zeros((4, 4))
    Ae[0, 0] = 1
    Ae[0, 1:] = (C @ A).flatten()
    Ae[1:, 1:] = A
    Be = np.zeros((4, 1))
    Be[0, 0] = (C @ B).item()
    Be[1:, :] = B
    Ce = np.array([[1, 0, 0, 0]])
    return Ae, Be, Ce

def solve_dare_iterative(Ae, Be, Ce, Qe_val, R_val, n_iter=5000):
    """Solve DARE by iterating the Riccati recursion."""
    n = Ae.shape[0]
    P = np.eye(n) * 0.001
    Q_mat = Ce.T @ (Qe_val * np.eye(1)) @ Ce
    for _ in range(n_iter):
        S = R_val + (Be.T @ P @ Be).item()
        K = (Be.T @ P @ Ae) / S
        P_new = Ae.T @ P @ Ae - Ae.T @ P @ Be @ K + Q_mat
        if np.max(np.abs(P_new - P)) < 1e-12:
            break
        P = P_new
    return P

def compute_preview_gains(Ae, Be, P, R_val, N):
    """Compute preview gains Gp(j) for j = 0, ..., N-1."""
    S = R_val + (Be.T @ P @ Be).item()
    K_fb = (Be.T @ P @ Ae) / S
    Acl = Ae - Be @ K_fb
    gains = np.zeros(N)
    Fj = np.eye(Ae.shape[0])
    for j in range(N):
        vec = Fj.T @ P @ np.array([[1], [0], [0], [0]])
        gains[j] = (Be.T @ vec).item() / S
        Fj = Fj @ Acl
    return gains

Ae, Be, Ce = build_augmented_system(T, z_c, g)
P = solve_dare_iterative(Ae, Be, Ce, Qe, R)

# Compute gains for different preview horizon lengths
horizon_list = [50, 100, 160]
colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
labels = []
for nh in horizon_list:
    labels.append(f"N={nh} ({nh*T:.1f}s)")

fig, axes = plt.subplots(2, 1, figsize=(8, 6))

for idx, N_h in enumerate(horizon_list):
    gp = compute_preview_gains(Ae, Be, P, R, N_h)
    j_arr = np.arange(N_h)
    t_arr = j_arr * T
    markerline, stemlines, baseline = axes[0].stem(
        t_arr, gp, linefmt=colors[idx],
        markerfmt='o', basefmt='k-', label=labels[idx]
    )
    markerline.set_markersize(2)
    stemlines.set_linewidth(0.8)

    gp_normalized = gp / np.max(np.abs(gp)) if np.max(np.abs(gp)) > 0 else gp
    axes[1].plot(t_arr, gp_normalized, color=colors[idx],
                 linewidth=1.5, label=labels[idx])

axes[0].set_xlabel('Preview time j*T (s)')
axes[0].set_ylabel('Preview gain Gp(j)')
axes[0].set_title('Preview Gains: Decay with Horizon')
axes[0].legend(fontsize=8)
axes[0].grid(True, alpha=0.3)

axes[1].set_xlabel('Preview time j*T (s)')
axes[1].set_ylabel('Normalized Gp(j)')
axes[1].set_title('Normalized Preview Gains')
axes[1].legend(fontsize=8)
axes[1].grid(True, alpha=0.3)
axes[1].axhline(y=0, color='k', linewidth=0.5)

plt.tight_layout()
buf = io.BytesIO()
plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
buf.seek(0)
img = base64.b64encode(buf.read()).decode('utf-8')
print(f'data:image/png;base64,{img}')
plt.close()

# Print summary statistics
print("=== Preview Gain Analysis ===")
for idx, N_h in enumerate(horizon_list):
    gp = compute_preview_gains(Ae, Be, P, R, N_h)
    peak = np.max(np.abs(gp))
    last = np.abs(gp[-1])
    ratio = last / peak if peak > 0 else 0
    print(f"N={N_h:3d} ({N_h*T:.1f}s): peak=|Gp|={peak:.4e}, "
          f"last=|Gp(N-1)|={last:.4e}, ratio={ratio:.4e}")
print()
print("The rapid decay confirms that distant future references")
print("contribute negligibly to the current control input.")
`}
/>

## Comparison with Model Predictive Control (MPC)

Preview control and MPC (covered in Chapter 10) both use future reference
information, but they differ fundamentally in how they compute the control
input:

| Aspect | Preview Control | MPC |
|--------|----------------|-----|
| **Optimization** | Infinite-horizon LQR solved **offline** | Finite-horizon QP solved **online** at each step |
| **Gains** | Pre-computed once, applied as a lookup | Re-computed every control cycle |
| **Speed** | Very fast at runtime (just multiply and sum) | Slower (requires solving an optimization problem) |
| **Constraints** | Cannot enforce constraints (e.g., ZMP bounds) | Can explicitly enforce ZMP and actuation limits |
| **Flexibility** | Fixed linear model only | Can incorporate nonlinear models |

In essence, preview control can be viewed as an **unconstrained MPC** with
a pre-computed closed-form solution. When constraints are not active (e.g.,
the ZMP reference is well within the support polygon), both methods produce
nearly identical results. MPC becomes necessary when the robot must walk
near its physical limits or handle unexpected disturbances.

## Advantages and Limitations

**Advantages:**
- Produces smooth CoM trajectories
- Analytically derived optimal gains
- Computationally efficient (gains computed offline)
- Works well for flat terrain walking

**Limitations:**
- Linear model only (constant CoM height)
- Fixed preview horizon
- Cannot handle large perturbations online
- Assumes pre-planned footsteps

## References

- S. Kajita et al., "[Biped Walking Pattern Generation by using Preview Control of Zero-Moment Point](https://doi.org/10.1109/ROBOT.2003.1241826)," *Proc. IEEE ICRA*, 2003.
- T. Katayama et al., "[Design of an optimal controller for a discrete-time system subject to previewable demand](https://doi.org/10.1080/0020718508961156)," *Int. J. Control*, 1985.

<InteractiveDemo title="Preview Control Visualization">
  <p className="text-sm text-gray-500">
    Interactive preview control with adjustable preview window coming soon.
  </p>
</InteractiveDemo>
